{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import time \n",
    "device =torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Experiments/U2net/U2N2T_WITH_ESRGAN_bacth_8_epoch_300_with_diceLoss/Miche_model_2023_05_02_23:00:18_val_iou0.798.pt\")\n",
    "\n",
    "\n",
    "val_images = \"/home/nipun/Documents/Uni_Malta/Datasets/Datasets/Miche/MICHE_MULTICLASS/Dataset/val_img\"\n",
    "\n",
    "val_masks =  \"/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Experiments/utils/Masks_with_256_val\" \n",
    "n_classes = 3\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "valid_x = sorted(\n",
    "        glob(f\"{val_images}/*\"))\n",
    "valid_y = sorted(\n",
    "        glob(f\"{val_masks }/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iris(Dataset):\n",
    "    def __init__(self,images,masks,transform = None):\n",
    "        self.transforms = transform\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        \n",
    "        # print(self.masks[index])\n",
    "        image = Image.open(self.images[index])\n",
    "        img = np.array(image.resize((64,64)))\n",
    "        \n",
    "        mask = Image.open(self.masks[index])\n",
    "        mask = np.array(mask.resize((256,256)))\n",
    "        \n",
    "               \n",
    "        if self.transforms is not None:\n",
    "            aug = self.transforms(image=img,mask=mask)\n",
    "            img = aug['image']\n",
    "            mask = aug['mask']\n",
    "        return img,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(test_x,test_y,val_transform,batch_size=1,shuffle=True,pin_memory=True):\n",
    "    \n",
    "    val_data  = Iris(test_x,test_y,transform =val_transform)\n",
    "    test_batch = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False,drop_last=True)\n",
    "    return test_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.augmentations.transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "val_batch = get_images(valid_x,valid_y,transform,batch_size=batch_size)\n",
    "\n",
    "val_cls  = Iris(valid_x,valid_y,transform =transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "batch_size = 1\n",
    "\n",
    "img_resize = 256\n",
    "\n",
    "colors = [ [  0,   0,   0],[0,255,0],[0,0,255]]\n",
    "label_colours = dict(zip(range(n_classes), colors))\n",
    "\n",
    "valid_classes = [0,85, 170]\n",
    "class_names = [\"Background\",\"Pupil\",\"Iris\"]\n",
    "\n",
    "\n",
    "class_map = dict(zip(valid_classes, range(len(valid_classes))))\n",
    "n_classes=len(valid_classes)\n",
    "\n",
    "\n",
    "def decode_segmap(temp):\n",
    "    #convert gray scale to color\n",
    "    # temp=temp.numpy()\n",
    "    r = temp.copy()\n",
    "    g = temp.copy()\n",
    "    b = temp.copy()\n",
    "    for l in range(0, n_classes):\n",
    "        r[temp == l] = label_colours[l][0]\n",
    "        g[temp == l] = label_colours[l][1]\n",
    "        b[temp == l] = label_colours[l][2]\n",
    "\n",
    "    rgb = np.zeros((temp.shape[0], temp.shape[1], 3))\n",
    "    rgb[:, :, 0] = r / 255.0\n",
    "    rgb[:, :, 1] = g / 255.0\n",
    "    rgb[:, :, 2] = b / 255.0\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    total_bg = 0\n",
    "    total_pupil = 0\n",
    "    total_iris = 0\n",
    "    total_iou = 0 \n",
    "    for i in range(len(val_batch)):\n",
    "        image,mask = val_cls[i]\n",
    "        \n",
    "        \n",
    "        bg_iou,pupil_iou,iris_iou= mean_iou(image=image,mask=mask)\n",
    "        \n",
    "        # print(bg_iou,pupil_iou,iris_iou) \n",
    "        \n",
    "        total_bg += bg_iou\n",
    "        total_pupil += pupil_iou\n",
    "        total_iris +=iris_iou\n",
    "        \n",
    "        # if i ==1:\n",
    "        #     break\n",
    "    return total_bg/len(val_batch),total_pupil/len(val_batch),total_iris/len(val_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "eps = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou(image,mask):\n",
    "    \n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    \n",
    "    image = image.unsqueeze(0)\n",
    "    mask = mask.unsqueeze(0) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "        model_output,_,_,_,_,_,_ = model(image)\n",
    "        \n",
    "        predicted_label = F.softmax(model_output,dim=1)\n",
    "        predicted_label = torch.argmax(predicted_label,dim=1)\n",
    "        \n",
    "        predicted_label = predicted_label.contiguous().view(-1) # 65536\n",
    "        mask = mask.contiguous().view(-1)  # 65536\n",
    "        \n",
    "        \n",
    "        iou_single_class = []\n",
    "        \n",
    "        for class_member in range(0,n_classes):\n",
    "            # print(class_member)\n",
    "            true_predicted_class = predicted_label==class_member\n",
    "            true_label = mask == class_member\n",
    "            \n",
    "            if true_label.long().sum().item() == 0:\n",
    "                iou_single_class.append(np.nan)\n",
    "            \n",
    "            else:\n",
    "                intersection = (torch.logical_and(\n",
    "                    true_predicted_class,\n",
    "                    true_label\n",
    "                ).sum().float().item() )\n",
    "                \n",
    "                union = (torch.logical_or(\n",
    "                    true_predicted_class,\n",
    "                    true_label\n",
    "                ).sum().float().item())\n",
    "                \n",
    "                iou = (intersection +eps)/(union +eps)\n",
    "                \n",
    "                iou_single_class.append(iou)\n",
    "            \n",
    "    return iou_single_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nipun/.local/lib/python3.10/site-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "total_bg,total_pupil,total_iris = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9825123014910376 0.6446349500796045 0.8550768371936728\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(total_bg,total_pupil,total_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_163577/1841278927.py:2: DeprecationWarning: Please use `distance_transform_edt` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n",
      "  from scipy.ndimage.morphology import distance_transform_edt as edt\n"
     ]
    }
   ],
   "source": [
    "from custom_model import  U2NET\n",
    "from scipy.ndimage.morphology import distance_transform_edt as edt\n",
    "from scipy.ndimage import convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HausdorffDTLoss(nn.Module):\n",
    "    \"\"\"Binary Hausdorff loss based on distance transform\"\"\"\n",
    "\n",
    "    def __init__(self, alpha=2.0, **kwargs):\n",
    "        super(HausdorffDTLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def distance_field(self, img: np.ndarray) -> np.ndarray:\n",
    "        field = np.zeros_like(img)\n",
    "\n",
    "        for batch in range(len(img)):\n",
    "            fg_mask = img[batch] > 0.5\n",
    "\n",
    "            if fg_mask.any():\n",
    "                bg_mask = ~fg_mask\n",
    "\n",
    "                fg_dist = edt(fg_mask)\n",
    "                bg_dist = edt(bg_mask)\n",
    "\n",
    "                field[batch] = fg_dist + bg_dist\n",
    "\n",
    "        return field\n",
    "\n",
    "    def forward(\n",
    "        self, pred: torch.Tensor, target: torch.Tensor, debug=False\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Uses one binary channel: 1 - fg, 0 - bg\n",
    "        pred: (b, 1, x, y, z) or (b, 1, x, y)\n",
    "        target: (b, 1, x, y, z) or (b, 1, x, y)\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "    \n",
    "        assert pred.dim() == 4 or pred.dim() == 5, \"Only 2D and 3D supported\"\n",
    "        assert (\n",
    "            pred.dim() == target.dim()\n",
    "        ), \"Prediction and target need to be of same dimension\"\n",
    "\n",
    "        # pred = torch.sigmoid(pred)\n",
    "\n",
    "        pred_dt = torch.from_numpy(self.distance_field(pred.detach().cpu().numpy())).float()\n",
    "        target_dt = torch.from_numpy(self.distance_field(target.detach().cpu().numpy())).float()\n",
    "\n",
    "        pred_error = (pred - target) ** 2\n",
    "        distance = pred_dt ** self.alpha + target_dt ** self.alpha\n",
    "\n",
    "        dt_field = pred_error * distance\n",
    "        loss = dt_field.mean()\n",
    "\n",
    "        if debug:\n",
    "            return (\n",
    "                loss.cpu().numpy(),\n",
    "                (\n",
    "                    dt_field.cpu().numpy()[0, 0],\n",
    "                    pred_error.cpu().numpy()[0, 0],\n",
    "                    distance.cpu().numpy()[0, 0],\n",
    "                    pred_dt.cpu().numpy()[0, 0],\n",
    "                    target_dt.cpu().numpy()[0, 0],\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HausdorffDistance:\n",
    "    def hd_distance(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        if np.count_nonzero(x) == 0 or np.count_nonzero(y) == 0:\n",
    "            return np.array([np.Inf])\n",
    "\n",
    "        indexes = np.nonzero(x)\n",
    "        distances = edt(np.logical_not(y))\n",
    "        \n",
    "        print(distances)\n",
    "        \n",
    "        \n",
    "        print(np.array(np.max(distances[indexes])))\n",
    "\n",
    "        return np.array(np.max(distances[indexes]))\n",
    "    \n",
    "    \n",
    "    def compute(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        # assert (\n",
    "        #     pred.shape[1] == 1 and target.shape[1] == 1\n",
    "        # ), \"Only binary channel supported\"\n",
    "\n",
    "        pred = (pred > 0.5)\n",
    "        target = (target > 0.5)\n",
    "\n",
    "        right_hd = torch.from_numpy(\n",
    "            self.hd_distance(pred.cpu().numpy(), target.cpu().numpy())  # 1.4142135623730951\n",
    "        ).float()\n",
    "\n",
    "        left_hd = torch.from_numpy(\n",
    "            self.hd_distance(target.cpu().numpy(), pred.cpu().numpy())\n",
    "        ).float()\n",
    "\n",
    "        return torch.max(right_hd, left_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.randn(8,3,256,256)\n",
    "\n",
    "mask = torch.ones_like(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = U2NET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nipun/.local/lib/python3.10/site-packages/torch/nn/functional.py:3722: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pred_output = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.sigmoid(pred_output[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = HausdorffDTLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46.9851, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(pred,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "disatance = HausdorffDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([inf])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disatance.compute(pred,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('LuminEye')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0a565227b7b463d99e303b82d66a46fc21535ffbac57e09021a6b5954f09e13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
