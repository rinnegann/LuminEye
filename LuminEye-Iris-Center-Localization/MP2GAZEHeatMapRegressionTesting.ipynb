{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
    "from basicsr.utils.download_util import load_file_from_url\n",
    "from torchvision import transforms  \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import time\n",
    "from imutils import face_utils\n",
    "from scipy.spatial import distance as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe\n",
    "from BaseModels.resnetModels import BB_model\n",
    "from BaseModels.efficientnetModels import BB_model\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from scipy.spatial import distance\n",
    "from BaseModels.unet_model import  UNET\n",
    "# device = \"cpu\"\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \"\"\"Load Regression model\n",
    "\n",
    "    Args:\n",
    "        model_path (_str_): _model path_\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "        _torch model_: _RESNET model_\n",
    "    \"\"\"\n",
    "\n",
    "    model = torch.load(model_path,map_location=device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# Latest Model\n",
    "# regression_model_path = \"/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Segmentation/Regression_model_1.140251636505127.pth\"\n",
    "\n",
    "# Mix Dataset\n",
    "# regression_model_path = '/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/Regression_model_1.487574208665777.pth'\n",
    "\n",
    "# regression_model_path = \"/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/RecentModels/SpheroPipeLine/Resnet_32_IMG_SIZE__32/Regression_model_0.25639680131442016.pth\"\n",
    "\n",
    "# regression_model_path = \"/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/Trained_Models/Resnet_32_IMG_SIZE__32/Regression_model_0.25639680131442016.pth\"\n",
    "\n",
    "# regression_model_path = \"RecentModels/BioGi4eH2head/Regression_model_0.7620949026704394.pth\"\n",
    "\n",
    "# regression_model_path = \"RecentModels/SpheroPipeLine/Resnet_32_IMG_SIZE__32/Regression_model_0.25639680131442016.pth\"\n",
    "\n",
    "# regression_model_path = \"/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/RecentModelsonGpu/RecentModels/AllDataset/Regression_model_1.4074174204430023.pth\"\n",
    "\n",
    "# regression_model_path = \"/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/RecentModelsonGpu/Recent_EffcientNetModels/EfficientNet1_6_smoothl1loss_batch_64.pt\"\n",
    "\n",
    "\n",
    "# regression_model_path = \"/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/RecentModelsonGpu/Recent_EffcientNetModels/EfficientNet1_6_smoothl1loss_batch_256.pt\"\n",
    "\n",
    "\n",
    "# regression_model_path = \"RecentModelsonGpu/Recent_EffcientNetModels/Regression_EffcientNet__epoch_500_SmoothL1Loss_summation_batch_256_resize_64_for_gi4e_bioid_h2head_1.52.pt\"\n",
    "\n",
    "# regression_model_path = \"RecentModelsonGpu/Recent_EffcientNetModels/EfficientNetWingLossV1.pt\"\n",
    "\n",
    "# regression_model_path = 'ResnetBaseWithMSEMEANwithoughtCoordConv/checkpoint.pt'\n",
    "\n",
    "\n",
    "regression_model_path = 'HeatMap_Regression/HeatMapRegressionModel.pth'\n",
    "\n",
    "REGRESSION_MODEL = load_model(\n",
    "    model_path=regression_model_path)\n",
    "\n",
    "\n",
    "\n",
    "RESIZE_AMT = 256\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= count_parameters(REGRESSION_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31043521"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioID\n",
    "val_csv_path = \"/home/nipun/Documents/Uni_Malta/Datasets/CenterRegression/MP2GAZE/AllCoordinatesMp2GazeTest.csv\"\n",
    "\n",
    "\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>DataSet Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPIIGaze/Data/Original/p00/day02/0350.jpg\"</td>\n",
       "      <td>[576.75131084363, 446.9430824441167, 595.62107...</td>\n",
       "      <td>MP2GAZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MPIIGaze/Data/Original/p00/day23/0201.jpg\"</td>\n",
       "      <td>[629.1027244977723, 418.5422721626321, 649.159...</td>\n",
       "      <td>MP2GAZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MPIIGaze/Data/Original/p00/day22/0437.jpg\"</td>\n",
       "      <td>[519.3837103984533, 379.3424773235636, 551.963...</td>\n",
       "      <td>MP2GAZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MPIIGaze/Data/Original/p00/day34/0296.jpg\"</td>\n",
       "      <td>[563.4499942709884, 374.6517620194357, 591.877...</td>\n",
       "      <td>MP2GAZE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MPIIGaze/Data/Original/p00/day10/0198.jpg\"</td>\n",
       "      <td>[659.4630047049818, 463.58724173032533, 685.19...</td>\n",
       "      <td>MP2GAZE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ImageName  \\\n",
       "0  MPIIGaze/Data/Original/p00/day02/0350.jpg\"   \n",
       "1  MPIIGaze/Data/Original/p00/day23/0201.jpg\"   \n",
       "2  MPIIGaze/Data/Original/p00/day22/0437.jpg\"   \n",
       "3  MPIIGaze/Data/Original/p00/day34/0296.jpg\"   \n",
       "4  MPIIGaze/Data/Original/p00/day10/0198.jpg\"   \n",
       "\n",
       "                                         Coordinates DataSet Type  \n",
       "0  [576.75131084363, 446.9430824441167, 595.62107...      MP2GAZE  \n",
       "1  [629.1027244977723, 418.5422721626321, 649.159...      MP2GAZE  \n",
       "2  [519.3837103984533, 379.3424773235636, 551.963...      MP2GAZE  \n",
       "3  [563.4499942709884, 374.6517620194357, 591.877...      MP2GAZE  \n",
       "4  [659.4630047049818, 463.58724173032533, 685.19...      MP2GAZE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectImgDir(datasetType:str):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if datasetType == \"MP2GAZE\":\n",
    "        return \"/home/nipun/Documents/Uni_Malta/Datasets/\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif datasetType ==\"i2head\":\n",
    "        return \"/home/nipun/Documents/Uni_Malta/Datasets/\"\n",
    "        \n",
    "    elif datasetType == \"GI4E\":\n",
    "        \n",
    "        return \"/home/nipun/Documents/Uni_Malta/Datasets/gi4e_database/images/\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap2argmax(heatmap, scale=False):\n",
    "    N, C, H, W = heatmap.shape\n",
    "    index = heatmap.view(N,C,1,-1).argmax(dim=-1)\n",
    "    pts = torch.cat([index%W, index//W], dim=2)\n",
    "    \n",
    "    if scale:\n",
    "        scale = torch.Tensor([W,H], device=heatmap.device)\n",
    "        pts = _scale(pts, scale)\n",
    "    \n",
    "    return pts\n",
    "\n",
    "\n",
    "def _scale(p, s): return 2 * (p / s) - 1\n",
    "\n",
    "\n",
    "def prediction_image(model,image):\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        \n",
    "        img = image[:,:,::-1]\n",
    "        \n",
    "        \n",
    "        img = cv2.resize(img,(RESIZE_AMT,RESIZE_AMT))\n",
    "        \n",
    "        img = img/255.0\n",
    "        \n",
    "        img = torch.tensor(img,dtype=torch.float32).permute(2,0,1)\n",
    "        \n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "                out_coord =heatmap2argmax(model(img).view(-1,1,256,256))\n",
    "        \n",
    "        print()\n",
    "        print(out_coord)\n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        img = img.squeeze(0)\n",
    "\n",
    "        image = transforms.ToPILImage()\n",
    "        \n",
    "        \n",
    "        pred_coord = out_coord.detach().cpu().numpy()[0][0]\n",
    "        \n",
    "        return image,pred_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropeyes(image, inner_array, outer_array):\n",
    "\n",
    "    arr = {\"top_left\": [inner_array[0]-5, inner_array[1]-20],\n",
    "           \"bottom_right\": [outer_array[0]+5, outer_array[1]+20]}\n",
    "\n",
    "    return image[arr[\"top_left\"][1]:arr[\"bottom_right\"][1], arr[\"top_left\"][0]:arr[\"bottom_right\"][0]], arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def rescale_coordinate(coord,original_image,resize_amt):\n",
    "    \n",
    "    h,w = original_image.shape[:2]\n",
    "    coord[0] = int((coord[0]/resize_amt) * w)\n",
    "    coord[1] = int((coord[1]/resize_amt) * h)\n",
    "    \n",
    "    return coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleCoorinatesToOriginalImage(pred_coords,eye_margin):\n",
    "    \n",
    "    # {'top_left': array([385, 214]), 'bottom_right': array([426, 226])}\n",
    "    \n",
    "    x1 = eye_margin[\"top_left\"][0] + pred_coords[0]\n",
    "    y1 = eye_margin[\"top_left\"][1] + pred_coords[1]\n",
    "    \n",
    "    return [x1,y1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateEuclideanDistance(coord1,coord2):\n",
    "    return (((coord1[0])-float(coord2[0]))^2  + (float(coord1[0])-float(coord2[0]))^2) ^ 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"/home/nipun/Documents/Uni_Malta/Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10273/913963836.py:4: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  pts = torch.cat([index%W, index//W], dim=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[[ 95, 112]]], device='cuda:0')\n",
      "\n",
      "tensor([[[112, 120]]], device='cuda:0')\n",
      "0.01681064060301542\n",
      "\n",
      "tensor([[[100, 108]]], device='cuda:0')\n",
      "\n",
      "tensor([[[110, 110]]], device='cuda:0')\n",
      "0.01499526786525223\n",
      "\n",
      "tensor([[[128,  99]]], device='cuda:0')\n",
      "\n",
      "tensor([[[136, 111]]], device='cuda:0')\n",
      "0.014134222674039373\n",
      "\n",
      "tensor([[[105, 119]]], device='cuda:0')\n",
      "\n",
      "tensor([[[142, 124]]], device='cuda:0')\n",
      "0.04407683212845996\n",
      "\n",
      "tensor([[[124, 107]]], device='cuda:0')\n",
      "\n",
      "tensor([[[136, 107]]], device='cuda:0')\n",
      "0.015607862099528717\n",
      "\n",
      "tensor([[[136,  99]]], device='cuda:0')\n",
      "\n",
      "tensor([[[140, 108]]], device='cuda:0')\n",
      "0.01563339910144465\n",
      "\n",
      "tensor([[[126, 119]]], device='cuda:0')\n",
      "\n",
      "tensor([[[144, 123]]], device='cuda:0')\n",
      "0.0055828472590842525\n",
      "\n",
      "tensor([[[136, 106]]], device='cuda:0')\n",
      "\n",
      "tensor([[[116, 105]]], device='cuda:0')\n",
      "0.0636665177057444\n",
      "\n",
      "tensor([[[124, 103]]], device='cuda:0')\n",
      "\n",
      "tensor([[[140, 105]]], device='cuda:0')\n",
      "0.0310860829281539\n",
      "\n",
      "tensor([[[130, 118]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124, 110]]], device='cuda:0')\n",
      "0.02520919395703246\n",
      "\n",
      "tensor([[[139, 113]]], device='cuda:0')\n",
      "\n",
      "tensor([[[120, 112]]], device='cuda:0')\n",
      "0.010234765854455706\n",
      "\n",
      "tensor([[[129, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[122, 102]]], device='cuda:0')\n",
      "0.014492753623188406\n",
      "\n",
      "tensor([[[137, 111]]], device='cuda:0')\n",
      "\n",
      "tensor([[[132, 102]]], device='cuda:0')\n",
      "0.006112464870141717\n",
      "\n",
      "tensor([[[149, 123]]], device='cuda:0')\n",
      "\n",
      "tensor([[[136, 120]]], device='cuda:0')\n",
      "0.006153059777521462\n",
      "\n",
      "tensor([[[150,  80]]], device='cuda:0')\n",
      "\n",
      "tensor([[[120, 100]]], device='cuda:0')\n",
      "0.058874480940946376\n",
      "\n",
      "tensor([[[142, 110]]], device='cuda:0')\n",
      "\n",
      "tensor([[[135, 102]]], device='cuda:0')\n",
      "0.009150659071358438\n",
      "\n",
      "tensor([[[110, 122]]], device='cuda:0')\n",
      "\n",
      "tensor([[[110, 108]]], device='cuda:0')\n",
      "0.006361173856841864\n",
      "\n",
      "tensor([[[137, 117]]], device='cuda:0')\n",
      "\n",
      "tensor([[[123, 109]]], device='cuda:0')\n",
      "0.007298492396656273\n",
      "\n",
      "tensor([[[111, 110]]], device='cuda:0')\n",
      "\n",
      "tensor([[[127, 105]]], device='cuda:0')\n",
      "0.019476824194835866\n",
      "\n",
      "tensor([[[148, 102]]], device='cuda:0')\n",
      "\n",
      "tensor([[[163, 114]]], device='cuda:0')\n",
      "0.07552818387981101\n",
      "\n",
      "tensor([[[130, 126]]], device='cuda:0')\n",
      "\n",
      "tensor([[[140, 122]]], device='cuda:0')\n",
      "0.014599551391877142\n",
      "\n",
      "tensor([[[108, 102]]], device='cuda:0')\n",
      "\n",
      "tensor([[[128, 100]]], device='cuda:0')\n",
      "0.01762213715841345\n",
      "\n",
      "tensor([[[129, 104]]], device='cuda:0')\n",
      "\n",
      "tensor([[[148, 117]]], device='cuda:0')\n",
      "0.030287492173690762\n",
      "\n",
      "tensor([[[117, 101]]], device='cuda:0')\n",
      "\n",
      "tensor([[[133, 104]]], device='cuda:0')\n",
      "0.025930969072302645\n",
      "\n",
      "tensor([[[136,  93]]], device='cuda:0')\n",
      "\n",
      "tensor([[[148,  97]]], device='cuda:0')\n",
      "0.021105314459656365\n",
      "\n",
      "tensor([[[114, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[132, 129]]], device='cuda:0')\n",
      "0.048762763800069824\n",
      "\n",
      "tensor([[[109, 113]]], device='cuda:0')\n",
      "\n",
      "tensor([[[129, 114]]], device='cuda:0')\n",
      "0.02011539100410523\n",
      "\n",
      "tensor([[[104, 102]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124,  91]]], device='cuda:0')\n",
      "0.04518646257309067\n",
      "\n",
      "tensor([[[126, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[129, 120]]], device='cuda:0')\n",
      "0.04224465836864636\n",
      "\n",
      "tensor([[[133,  95]]], device='cuda:0')\n",
      "\n",
      "tensor([[[146, 109]]], device='cuda:0')\n",
      "0.02863198757078279\n",
      "\n",
      "tensor([[[108,  90]]], device='cuda:0')\n",
      "\n",
      "tensor([[[132,  93]]], device='cuda:0')\n",
      "0.025400935844162628\n",
      "\n",
      "tensor([[[119, 114]]], device='cuda:0')\n",
      "\n",
      "tensor([[[150,  63]]], device='cuda:0')\n",
      "0.047907799138234806\n",
      "\n",
      "tensor([[[158, 162]]], device='cuda:0')\n",
      "\n",
      "tensor([[[138, 143]]], device='cuda:0')\n",
      "0.05830194018881583\n",
      "\n",
      "tensor([[[124, 101]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124, 118]]], device='cuda:0')\n",
      "0.016935913442378384\n",
      "\n",
      "tensor([[[123, 111]]], device='cuda:0')\n",
      "\n",
      "tensor([[[111, 115]]], device='cuda:0')\n",
      "0.03846095790563293\n",
      "\n",
      "tensor([[[128, 118]]], device='cuda:0')\n",
      "\n",
      "tensor([[[133, 122]]], device='cuda:0')\n",
      "0.016210296808748977\n",
      "\n",
      "tensor([[[140, 108]]], device='cuda:0')\n",
      "\n",
      "tensor([[[136, 104]]], device='cuda:0')\n",
      "0.010640405449734032\n",
      "\n",
      "tensor([[[133, 110]]], device='cuda:0')\n",
      "\n",
      "tensor([[[131, 106]]], device='cuda:0')\n",
      "0.014935149557952753\n",
      "\n",
      "tensor([[[109, 121]]], device='cuda:0')\n",
      "\n",
      "tensor([[[120, 112]]], device='cuda:0')\n",
      "0.009686167061350202\n",
      "\n",
      "tensor([[[125, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[140,  97]]], device='cuda:0')\n",
      "0.023596458909150436\n",
      "\n",
      "tensor([[[113, 142]]], device='cuda:0')\n",
      "\n",
      "tensor([[[109, 139]]], device='cuda:0')\n",
      "0.005882251173005375\n",
      "\n",
      "tensor([[[123, 117]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124, 116]]], device='cuda:0')\n",
      "0.01187367124356345\n",
      "\n",
      "tensor([[[127, 101]]], device='cuda:0')\n",
      "\n",
      "tensor([[[130,  95]]], device='cuda:0')\n",
      "0.016812065978477165\n",
      "\n",
      "tensor([[[126, 120]]], device='cuda:0')\n",
      "\n",
      "tensor([[[125, 111]]], device='cuda:0')\n",
      "0.019611613513818404\n",
      "\n",
      "tensor([[[115, 109]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124, 110]]], device='cuda:0')\n",
      "0.010959932487023821\n",
      "\n",
      "tensor([[[118, 108]]], device='cuda:0')\n",
      "\n",
      "tensor([[[119, 105]]], device='cuda:0')\n",
      "0.011497671238805652\n",
      "\n",
      "tensor([[[109, 113]]], device='cuda:0')\n",
      "\n",
      "tensor([[[122, 110]]], device='cuda:0')\n",
      "0.009820927516479828\n",
      "\n",
      "tensor([[[122, 113]]], device='cuda:0')\n",
      "\n",
      "tensor([[[136, 105]]], device='cuda:0')\n",
      "0.011681334327560295\n",
      "\n",
      "tensor([[[124, 110]]], device='cuda:0')\n",
      "\n",
      "tensor([[[125, 111]]], device='cuda:0')\n",
      "0.014846210376062518\n",
      "\n",
      "tensor([[[106, 108]]], device='cuda:0')\n",
      "\n",
      "tensor([[[118, 110]]], device='cuda:0')\n",
      "0.015612426691778635\n",
      "\n",
      "tensor([[[133, 103]]], device='cuda:0')\n",
      "\n",
      "tensor([[[140, 103]]], device='cuda:0')\n",
      "0.016027205229701\n",
      "\n",
      "tensor([[[118, 105]]], device='cuda:0')\n",
      "\n",
      "tensor([[[134, 112]]], device='cuda:0')\n",
      "0.00980203746722279\n",
      "\n",
      "tensor([[[125, 107]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124, 106]]], device='cuda:0')\n",
      "0.024558833620630077\n",
      "\n",
      "tensor([[[114, 118]]], device='cuda:0')\n",
      "\n",
      "tensor([[[130, 102]]], device='cuda:0')\n",
      "0.008333043996551019\n",
      "\n",
      "tensor([[[125, 118]]], device='cuda:0')\n",
      "\n",
      "tensor([[[136, 116]]], device='cuda:0')\n",
      "0.00978091590241809\n",
      "\n",
      "tensor([[[130, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124, 105]]], device='cuda:0')\n",
      "0.01385884583210106\n",
      "\n",
      "tensor([[[118, 112]]], device='cuda:0')\n",
      "\n",
      "tensor([[[ 89, 115]]], device='cuda:0')\n",
      "0.09322033898305085\n",
      "\n",
      "tensor([[[138, 126]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124, 112]]], device='cuda:0')\n",
      "0.05157715926423047\n",
      "\n",
      "tensor([[[128, 117]]], device='cuda:0')\n",
      "\n",
      "tensor([[[127, 120]]], device='cuda:0')\n",
      "0.009489015705159533\n",
      "\n",
      "tensor([[[116, 111]]], device='cuda:0')\n",
      "\n",
      "tensor([[[109,  99]]], device='cuda:0')\n",
      "0.014804664203952106\n",
      "\n",
      "tensor([[[102, 122]]], device='cuda:0')\n",
      "\n",
      "tensor([[[ 72, 105]]], device='cuda:0')\n",
      "0.05356715840055802\n",
      "\n",
      "tensor([[[150, 107]]], device='cuda:0')\n",
      "\n",
      "tensor([[[106, 110]]], device='cuda:0')\n",
      "0.07067806499764008\n",
      "\n",
      "tensor([[[121, 103]]], device='cuda:0')\n",
      "\n",
      "tensor([[[121, 103]]], device='cuda:0')\n",
      "0.014925373134328358\n",
      "\n",
      "tensor([[[136, 117]]], device='cuda:0')\n",
      "\n",
      "tensor([[[152, 115]]], device='cuda:0')\n",
      "0.03922322702763681\n",
      "\n",
      "tensor([[[113, 112]]], device='cuda:0')\n",
      "\n",
      "tensor([[[141, 112]]], device='cuda:0')\n",
      "0.04279454200297942\n",
      "\n",
      "tensor([[[129, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[120, 113]]], device='cuda:0')\n",
      "0.01904416463717214\n",
      "\n",
      "tensor([[[116, 125]]], device='cuda:0')\n",
      "\n",
      "tensor([[[122, 122]]], device='cuda:0')\n",
      "0.012393467389926256\n",
      "\n",
      "tensor([[[141, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[138, 122]]], device='cuda:0')\n",
      "0.009417841010583804\n",
      "\n",
      "tensor([[[112, 107]]], device='cuda:0')\n",
      "\n",
      "tensor([[[139, 112]]], device='cuda:0')\n",
      "0.0591175908533324\n",
      "\n",
      "tensor([[[118, 106]]], device='cuda:0')\n",
      "\n",
      "tensor([[[104, 100]]], device='cuda:0')\n",
      "0.017699115044247787\n",
      "\n",
      "tensor([[[134, 122]]], device='cuda:0')\n",
      "\n",
      "tensor([[[120, 116]]], device='cuda:0')\n",
      "0.010936311915413112\n",
      "\n",
      "tensor([[[138, 102]]], device='cuda:0')\n",
      "\n",
      "tensor([[[130, 106]]], device='cuda:0')\n",
      "0.00889372135904979\n",
      "\n",
      "tensor([[[116, 114]]], device='cuda:0')\n",
      "\n",
      "tensor([[[101,  99]]], device='cuda:0')\n",
      "0.018982732380846915\n",
      "\n",
      "tensor([[[122, 106]]], device='cuda:0')\n",
      "\n",
      "tensor([[[107, 106]]], device='cuda:0')\n",
      "0.0180150939644418\n",
      "\n",
      "tensor([[[113, 110]]], device='cuda:0')\n",
      "\n",
      "tensor([[[112, 115]]], device='cuda:0')\n",
      "0.02281227009624893\n",
      "\n",
      "tensor([[[117, 102]]], device='cuda:0')\n",
      "\n",
      "tensor([[[146, 106]]], device='cuda:0')\n",
      "0.08158569438683852\n",
      "\n",
      "tensor([[[140, 120]]], device='cuda:0')\n",
      "\n",
      "tensor([[[122, 118]]], device='cuda:0')\n",
      "0.02050661957987655\n",
      "\n",
      "tensor([[[ 94, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[116, 115]]], device='cuda:0')\n",
      "0.0503198535631926\n",
      "\n",
      "tensor([[[134, 122]]], device='cuda:0')\n",
      "\n",
      "tensor([[[126, 118]]], device='cuda:0')\n",
      "0.026130956801846985\n",
      "\n",
      "tensor([[[105, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[115, 112]]], device='cuda:0')\n",
      "0.05988990377257332\n",
      "\n",
      "tensor([[[136, 111]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124, 119]]], device='cuda:0')\n",
      "0.013336297284316557\n",
      "\n",
      "tensor([[[121, 111]]], device='cuda:0')\n",
      "\n",
      "tensor([[[115, 105]]], device='cuda:0')\n",
      "0.011984430354239597\n",
      "\n",
      "tensor([[[128, 117]]], device='cuda:0')\n",
      "\n",
      "tensor([[[120, 117]]], device='cuda:0')\n",
      "0.0128564869306645\n",
      "\n",
      "tensor([[[128, 117]]], device='cuda:0')\n",
      "\n",
      "tensor([[[112, 117]]], device='cuda:0')\n",
      "0.01487328031828116\n",
      "\n",
      "tensor([[[118, 118]]], device='cuda:0')\n",
      "\n",
      "tensor([[[132, 114]]], device='cuda:0')\n",
      "0.02080513367594894\n",
      "\n",
      "tensor([[[125, 118]]], device='cuda:0')\n",
      "\n",
      "tensor([[[133, 128]]], device='cuda:0')\n",
      "0.0441855446775722\n",
      "\n",
      "tensor([[[127,  95]]], device='cuda:0')\n",
      "\n",
      "tensor([[[120, 105]]], device='cuda:0')\n",
      "0.01499526786525223\n",
      "\n",
      "tensor([[[ 93, 110]]], device='cuda:0')\n",
      "\n",
      "tensor([[[104, 106]]], device='cuda:0')\n",
      "0.030989206908501328\n",
      "\n",
      "tensor([[[114, 101]]], device='cuda:0')\n",
      "\n",
      "tensor([[[113,  92]]], device='cuda:0')\n",
      "0.019460426107992847\n",
      "\n",
      "tensor([[[112, 109]]], device='cuda:0')\n",
      "\n",
      "tensor([[[112, 103]]], device='cuda:0')\n",
      "0.012713091355997266\n",
      "\n",
      "tensor([[[115, 102]]], device='cuda:0')\n",
      "\n",
      "tensor([[[124, 103]]], device='cuda:0')\n",
      "0.013790152245155451\n",
      "\n",
      "tensor([[[132,  97]]], device='cuda:0')\n",
      "\n",
      "tensor([[[142, 111]]], device='cuda:0')\n",
      "0.00768866894674349\n",
      "\n",
      "tensor([[[131, 103]]], device='cuda:0')\n",
      "\n",
      "tensor([[[133, 103]]], device='cuda:0')\n",
      "0.016933957229441753\n",
      "\n",
      "tensor([[[126, 100]]], device='cuda:0')\n",
      "\n",
      "tensor([[[146,  90]]], device='cuda:0')\n",
      "0.0660659813444278\n",
      "\n",
      "tensor([[[138, 120]]], device='cuda:0')\n",
      "\n",
      "tensor([[[156, 121]]], device='cuda:0')\n",
      "0.04758453167893643\n",
      "\n",
      "tensor([[[126, 126]]], device='cuda:0')\n",
      "\n",
      "tensor([[[148, 121]]], device='cuda:0')\n",
      "0.06033586037795675\n",
      "\n",
      "tensor([[[129, 111]]], device='cuda:0')\n",
      "\n",
      "tensor([[[125, 119]]], device='cuda:0')\n",
      "0.03366221139379705\n",
      "\n",
      "tensor([[[125, 121]]], device='cuda:0')\n",
      "\n",
      "tensor([[[130, 107]]], device='cuda:0')\n",
      "0.03534684324301841\n",
      "\n",
      "tensor([[[126, 119]]], device='cuda:0')\n",
      "\n",
      "tensor([[[130,  99]]], device='cuda:0')\n",
      "0.02243653128423514\n",
      "\n",
      "tensor([[[140, 121]]], device='cuda:0')\n",
      "\n",
      "tensor([[[136, 115]]], device='cuda:0')\n",
      "0.01663320290643224\n",
      "\n",
      "tensor([[[124, 137]]], device='cuda:0')\n",
      "\n",
      "tensor([[[154, 131]]], device='cuda:0')\n",
      "0.06016401703553469\n",
      "\n",
      "tensor([[[151, 105]]], device='cuda:0')\n",
      "\n",
      "tensor([[[133, 107]]], device='cuda:0')\n",
      "0.041665419516404734\n",
      "\n",
      "tensor([[[116, 109]]], device='cuda:0')\n",
      "\n",
      "tensor([[[118, 106]]], device='cuda:0')\n",
      "0.015339299776947408\n",
      "\n",
      "tensor([[[136, 121]]], device='cuda:0')\n",
      "\n",
      "tensor([[[140, 121]]], device='cuda:0')\n",
      "0.010750202576038455\n",
      "\n",
      "tensor([[[120, 121]]], device='cuda:0')\n",
      "\n",
      "tensor([[[121, 111]]], device='cuda:0')\n",
      "0.011224624202364815\n",
      "\n",
      "tensor([[[109, 115]]], device='cuda:0')\n",
      "\n",
      "tensor([[[118, 102]]], device='cuda:0')\n",
      "0.011316968255314816\n",
      "\n",
      "tensor([[[124, 104]]], device='cuda:0')\n",
      "\n",
      "tensor([[[132, 107]]], device='cuda:0')\n",
      "0.016666666666666666\n",
      "\n",
      "tensor([[[156, 121]]], device='cuda:0')\n",
      "\n",
      "tensor([[[137, 107]]], device='cuda:0')\n",
      "0.03788789454934623\n",
      "\n",
      "tensor([[[118, 103]]], device='cuda:0')\n",
      "\n",
      "tensor([[[144, 100]]], device='cuda:0')\n",
      "0.024912570161584238\n",
      "\n",
      "tensor([[[113,  91]]], device='cuda:0')\n",
      "\n",
      "tensor([[[122,  98]]], device='cuda:0')\n",
      "0.026299402984029215\n",
      "\n",
      "tensor([[[120,  98]]], device='cuda:0')\n",
      "\n",
      "tensor([[[144, 103]]], device='cuda:0')\n",
      "0.011401611731735473\n",
      "\n",
      "tensor([[[124, 112]]], device='cuda:0')\n",
      "\n",
      "tensor([[[140, 120]]], device='cuda:0')\n",
      "0.020143939106994628\n",
      "\n",
      "tensor([[[111, 101]]], device='cuda:0')\n",
      "\n",
      "tensor([[[118, 102]]], device='cuda:0')\n",
      "0.026824018894244708\n",
      "\n",
      "tensor([[[111, 113]]], device='cuda:0')\n",
      "\n",
      "tensor([[[116, 104]]], device='cuda:0')\n",
      "0.019105412604086193\n",
      "\n",
      "tensor([[[132, 110]]], device='cuda:0')\n",
      "\n",
      "tensor([[[117, 106]]], device='cuda:0')\n",
      "0.009259259259259259\n",
      "\n",
      "tensor([[[137, 102]]], device='cuda:0')\n",
      "\n",
      "tensor([[[133,  95]]], device='cuda:0')\n",
      "0.02797355382280552\n",
      "\n",
      "tensor([[[124,  83]]], device='cuda:0')\n",
      "\n",
      "tensor([[[137,  95]]], device='cuda:0')\n",
      "0.04279291435387791\n",
      "\n",
      "tensor([[[133, 112]]], device='cuda:0')\n",
      "\n",
      "tensor([[[137, 119]]], device='cuda:0')\n",
      "0.024030547824275033\n",
      "\n",
      "tensor([[[123, 114]]], device='cuda:0')\n",
      "\n",
      "tensor([[[118,  89]]], device='cuda:0')\n",
      "0.012615597664022225\n",
      "\n",
      "tensor([[[137, 107]]], device='cuda:0')\n",
      "\n",
      "tensor([[[140, 104]]], device='cuda:0')\n",
      "0.020672455764868078\n",
      "\n",
      "tensor([[[123, 110]]], device='cuda:0')\n",
      "\n",
      "tensor([[[120,  92]]], device='cuda:0')\n",
      "0.011220737131265684\n",
      "\n",
      "tensor([[[132, 104]]], device='cuda:0')\n",
      "\n",
      "tensor([[[113, 101]]], device='cuda:0')\n",
      "0.03697466539056922\n",
      "\n",
      "tensor([[[132, 108]]], device='cuda:0')\n",
      "\n",
      "tensor([[[126, 100]]], device='cuda:0')\n",
      "0.009009009009009009\n",
      "\n",
      "tensor([[[146, 117]]], device='cuda:0')\n",
      "\n",
      "tensor([[[139, 118]]], device='cuda:0')\n",
      "0.01662056238286334\n",
      "\n",
      "tensor([[[144, 106]]], device='cuda:0')\n",
      "\n",
      "tensor([[[141,  91]]], device='cuda:0')\n",
      "0.013962069110799129\n",
      "\n",
      "tensor([[[133, 107]]], device='cuda:0')\n",
      "\n",
      "tensor([[[138, 112]]], device='cuda:0')\n",
      "0.02127178149057585\n",
      "\n",
      "tensor([[[112, 114]]], device='cuda:0')\n",
      "\n",
      "tensor([[[114, 116]]], device='cuda:0')\n",
      "0.012059138312498212\n",
      "\n",
      "tensor([[[129, 127]]], device='cuda:0')\n",
      "\n",
      "tensor([[[121, 119]]], device='cuda:0')\n",
      "0.027915976530222084\n"
     ]
    }
   ],
   "source": [
    "maximizedNormalizedError = []\n",
    "times_array = []\n",
    "for i, (_, rows) in enumerate(val_df.iterrows()):\n",
    "\n",
    "        bbox = [int(float(x)) for x in rows[\"Coordinates\"][1:-1].split(',')]\n",
    "\n",
    "        left_inner = bbox[0:2]\n",
    "        left_center = bbox[2:4]\n",
    "        left_outer = bbox[4:6]\n",
    "\n",
    "        right_inner = bbox[6:8]\n",
    "        right_center = bbox[8:10]\n",
    "        right_outer = bbox[10:12]\n",
    "\n",
    "        img_path = os.path.join(IMG_DIR, rows[\"ImageName\"][:-1])\n",
    "        # #\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "\n",
    "        IPD = distance.euclidean(left_center, right_center)\n",
    "        \n",
    "\n",
    "       \n",
    "\n",
    "        left_eye, Leye = cropeyes(img, left_inner, left_outer)\n",
    "        right_eye, Reye = cropeyes(img, right_inner, right_outer)\n",
    "        \n",
    "        start_time = datetime.datetime.now()\n",
    "        _, pred_l_eye = prediction_image(\n",
    "            model=REGRESSION_MODEL, image=left_eye)\n",
    "        \n",
    "        end_time = datetime.datetime.now()\n",
    "        \n",
    "        times_array.append((end_time-start_time).total_seconds())\n",
    "\n",
    "        _, pred_r_eye = prediction_image(\n",
    "            model=REGRESSION_MODEL, image=right_eye)\n",
    "        \n",
    "        \n",
    "        pred_l_eye = rescale_coordinate(pred_l_eye, left_eye, RESIZE_AMT)\n",
    "\n",
    "        pred_r_eye = rescale_coordinate(pred_r_eye, right_eye, RESIZE_AMT)\n",
    "        \n",
    "        \n",
    "        pred_l_eye_toOriginaImage = scaleCoorinatesToOriginalImage(\n",
    "            pred_l_eye, Leye)\n",
    "        pred_r_eye_toOriginaImage = scaleCoorinatesToOriginalImage(\n",
    "            pred_r_eye, Reye)\n",
    "        \n",
    "        \n",
    "        cv2.circle(img, (int(pred_l_eye_toOriginaImage[0]), int(\n",
    "            pred_l_eye_toOriginaImage[1])), 1, (0, 255, 0), -1)\n",
    "\n",
    "        cv2.circle(img, (int(pred_r_eye_toOriginaImage[0]), int(\n",
    "            pred_r_eye_toOriginaImage[1])), 1, (0, 255, 0), -1)\n",
    "        \n",
    "        \n",
    "        cv2.circle(img, (int(left_inner[0]), int(\n",
    "            left_inner[1])), 1, (0, 0, 255), -1)\n",
    "        cv2.circle(img, (int(left_center[0]), int(\n",
    "            left_center[1])), 1, (0, 0, 255), -1)\n",
    "        cv2.circle(img, (int(left_outer[0]), int(\n",
    "            left_outer[1])), 1, (0, 0, 255), -1)\n",
    "\n",
    "        cv2.circle(img, (int(right_inner[0]), int(\n",
    "            right_inner[1])), 1, (0, 0, 255), -1)\n",
    "        cv2.circle(img, (int(right_center[0]), int(\n",
    "            right_center[1])), 1, (0, 0, 255), -1)\n",
    "        cv2.circle(img, (int(right_outer[0]), int(\n",
    "            right_outer[1])), 1, (0, 0, 255), -1)\n",
    "        \n",
    "         \n",
    "          \n",
    "        left_eye_euclidea_distance = distance.euclidean(\n",
    "            pred_l_eye_toOriginaImage, left_center)\n",
    "\n",
    "        right_eye_euclidea_distance = distance.euclidean(\n",
    "            pred_r_eye_toOriginaImage, right_center)\n",
    "        \n",
    "        eMax = max(left_eye_euclidea_distance, right_eye_euclidea_distance)/IPD\n",
    "\n",
    "        print(eMax)\n",
    "\n",
    "        maximizedNormalizedError.append(eMax)\n",
    "    \n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckForLess(list1, val):\n",
    "    \n",
    "    l1 = []\n",
    "    for x in list1:\n",
    "        \n",
    "        if x <= val:\n",
    "            l1.append(x)\n",
    "    return l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.043262,\n",
       " 0.028022,\n",
       " 0.030422,\n",
       " 0.046971,\n",
       " 0.028594,\n",
       " 0.023727,\n",
       " 0.027655,\n",
       " 0.026465,\n",
       " 0.028114,\n",
       " 0.026544,\n",
       " 0.026883,\n",
       " 0.025137,\n",
       " 0.026246,\n",
       " 0.027059,\n",
       " 0.026753,\n",
       " 0.02587,\n",
       " 0.026226,\n",
       " 0.025693,\n",
       " 0.025826,\n",
       " 0.026751,\n",
       " 0.023445,\n",
       " 0.026438,\n",
       " 0.03947,\n",
       " 0.027644,\n",
       " 0.026444,\n",
       " 0.024697,\n",
       " 0.025728,\n",
       " 0.026153,\n",
       " 0.026187,\n",
       " 0.027228,\n",
       " 0.024485,\n",
       " 0.026635,\n",
       " 0.027244,\n",
       " 0.02536,\n",
       " 0.026021,\n",
       " 0.023219,\n",
       " 0.025985,\n",
       " 0.026525,\n",
       " 0.026225,\n",
       " 0.028133,\n",
       " 0.025227,\n",
       " 0.025945,\n",
       " 0.026264,\n",
       " 0.027051,\n",
       " 0.023557,\n",
       " 0.023789,\n",
       " 0.026389,\n",
       " 0.02693,\n",
       " 0.024372,\n",
       " 0.027405,\n",
       " 0.025934,\n",
       " 0.025696,\n",
       " 0.027585,\n",
       " 0.025679,\n",
       " 0.027138,\n",
       " 0.025694,\n",
       " 0.024566,\n",
       " 0.024992,\n",
       " 0.026032,\n",
       " 0.025609,\n",
       " 0.024113,\n",
       " 0.026636,\n",
       " 0.025075,\n",
       " 0.025723,\n",
       " 0.026347,\n",
       " 0.027111,\n",
       " 0.023689,\n",
       " 0.026305,\n",
       " 0.026486,\n",
       " 0.026191,\n",
       " 0.027458,\n",
       " 0.024047,\n",
       " 0.027768,\n",
       " 0.025479,\n",
       " 0.027397,\n",
       " 0.027315,\n",
       " 0.025814,\n",
       " 0.025592,\n",
       " 0.026707,\n",
       " 0.02787,\n",
       " 0.023927,\n",
       " 0.027581,\n",
       " 0.025096,\n",
       " 0.024976,\n",
       " 0.02567,\n",
       " 0.026029,\n",
       " 0.026666,\n",
       " 0.026585,\n",
       " 0.027547,\n",
       " 0.024179,\n",
       " 0.025194,\n",
       " 0.028106,\n",
       " 0.024575,\n",
       " 0.026805,\n",
       " 0.026629,\n",
       " 0.024065,\n",
       " 0.02631,\n",
       " 0.027739,\n",
       " 0.026044,\n",
       " 0.024535,\n",
       " 0.027939,\n",
       " 0.027516,\n",
       " 0.025293,\n",
       " 0.02392,\n",
       " 0.026717,\n",
       " 0.026552,\n",
       " 0.025818,\n",
       " 0.025922,\n",
       " 0.031606,\n",
       " 0.024544,\n",
       " 0.028011,\n",
       " 0.026721,\n",
       " 0.027193,\n",
       " 0.025569,\n",
       " 0.02366,\n",
       " 0.025675,\n",
       " 0.026887,\n",
       " 0.025513,\n",
       " 0.025317,\n",
       " 0.025127,\n",
       " 0.024027,\n",
       " 0.02609,\n",
       " 0.026631,\n",
       " 0.026879,\n",
       " 0.025061,\n",
       " 0.02413,\n",
       " 0.02618,\n",
       " 0.026411]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_0_25 = CheckForLess(maximizedNormalizedError,0.25)\n",
    "\n",
    "e_0_05 = CheckForLess(maximizedNormalizedError,0.05)\n",
    "\n",
    "e_0_1 = CheckForLess(maximizedNormalizedError,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(e_0_25)/len(maximizedNormalizedError)) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(e_0_05)/len(maximizedNormalizedError)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.28125"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_0_1)/len((maximizedNormalizedError)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(img[:,:,::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(right_eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1713519254.4548721\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1713519265.5901499\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.13527774810791"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "ms = time.time_ns() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = b - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(delta.total_seconds() * 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "a = \n",
    "b = datetime.datetime.now()\n",
    "c = b - a\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path =  \"/home/nipun/Documents/Uni_Malta/Datasets/columbia_gaze_data_set/Columbia Gaze Data Set/0039/0039_2m_0P_10V_5H.jpg\"\n",
    "\n",
    "frame = cv2.imread(img_path)\n",
    "\n",
    "plt.imshow(frame[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4e-05"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # MediaPipe\n",
    "shape_array = captureFaceLandmarks(frame)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye, right_eye,Leye,Reye = cropped_image(frame, shape_array)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(left_eye[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(right_eye[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left = \"/home/nipun/Documents/Uni_Malta/Datasets/Center_Regression/MP2GAZE/Images/417_left.png\"\n",
    "\n",
    "# left_eye = cv2.imread(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,pred_l_eye = prediction_image(model=REGRESSION_MODEL,image=left_eye)\n",
    "        \n",
    "        \n",
    "_,pred_r_eye = prediction_image(model=REGRESSION_MODEL,image=right_eye)\n",
    "\n",
    "\n",
    "pred_l_eye = rescale_coordinate(pred_l_eye,left_eye,RESIZE_AMT)\n",
    "\n",
    "pred_r_eye = rescale_coordinate(pred_r_eye,right_eye,RESIZE_AMT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.circle(left_eye,(int(pred_l_eye[0]),int(pred_l_eye[1])),1,(0,255,0),-1)\n",
    "cv2.circle(right_eye,(int(pred_r_eye[0]),int(pred_r_eye[1])),1,(0,255,0),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(left_eye[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(right_eye[:,:,::-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoordConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    # generate all of the input images\n",
    "    n_samples = 56 ** 2\n",
    "    onehots = np.pad(np.eye(n_samples).reshape((n_samples, 1, 56, 56)), ((0,0), (0, 0), (4,4), (4,4)), \"constant\")\n",
    "    onehots = torch.from_numpy(onehots).float()\n",
    "    with torch.no_grad():\n",
    "        conv = nn.Conv2d(1, 1, kernel_size=9, padding=4, stride=1)\n",
    "        conv.weight.data.fill_(1)\n",
    "        conv.bias.data.fill_(0)\n",
    "        dataset_x = conv(onehots)\n",
    "    y_i = torch.arange(56).view(56, 1).repeat(1, 56).view(-1, 1)\n",
    "    y_j = torch.arange(56).repeat(56, 1).view(-1, 1)\n",
    "    dataset_y = torch.cat((y_i, y_j), dim=1)\n",
    "\n",
    "    # split the dataset tensor into train, test sets\n",
    "    sample_order = np.arange(n_samples)\n",
    "    \n",
    "    np.random.shuffle(sample_order)\n",
    "    train_idxes = sample_order[:2352]\n",
    "    test_idxes = sample_order[2352:]\n",
    "\n",
    "    train_x = dataset_x[train_idxes]\n",
    "    train_y = dataset_y[train_idxes] \n",
    "    test_x = dataset_x[test_idxes]\n",
    "    test_y = dataset_y[test_idxes]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 8**2\n",
    "x = np.pad(np.ones((64,64)).reshape(samples,1,8,8), ((2,2), (0, 0), (4,4), (4,4)),\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[63]\n",
    "\n",
    "\n",
    "# array([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "#         [0., 0., 0., 0., 0., 0., 0., 1.]]])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8).view(8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8).view(8,1).repeat(1,56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8).view(8,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(8).view(8,1).repeat(1,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "def generate_data():\n",
    "    # generate all of the input images\n",
    "    n_samples = 56 ** 2\n",
    "    onehots = np.pad(np.eye(n_samples).reshape((n_samples, 1, 56, 56)), ((0,0), (0, 0), (4,4), (4,4)), \"constant\")\n",
    "    onehots = torch.from_numpy(onehots).float()\n",
    "    with torch.no_grad():\n",
    "        conv = nn.Conv2d(1, 1, kernel_size=9, padding=4, stride=1)\n",
    "        conv.weight.data.fill_(1)\n",
    "        conv.bias.data.fill_(0)\n",
    "        dataset_x = conv(onehots)\n",
    "    y_i = torch.arange(56).view(56, 1).repeat(1, 56).view(-1, 1)\n",
    "    y_j = torch.arange(56).repeat(56, 1).view(-1, 1)\n",
    "    dataset_y = torch.cat((y_i, y_j), dim=1)\n",
    "\n",
    "    # split the dataset tensor into train, test sets\n",
    "    sample_order = np.arange(n_samples)\n",
    "    \n",
    "    np.random.shuffle(sample_order)\n",
    "    train_idxes = sample_order[:2352]\n",
    "    test_idxes = sample_order[2352:]\n",
    "\n",
    "    train_x = dataset_x[train_idxes]\n",
    "    train_y = dataset_y[train_idxes] \n",
    "    test_x = dataset_x[test_idxes]\n",
    "    test_y = dataset_y[test_idxes]\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "\n",
    "class CoordConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, device, in_channels, out_channels, kernel_size, padding, stride, input_size):\n",
    "        super(CoordConv2d, self).__init__()\n",
    "        self.device = device\n",
    "        self.cc_xy = self.make_channels(input_size)\n",
    "        self.conv = nn.Conv2d(in_channels+2, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "\n",
    "    def make_channels(self, input_size):\n",
    "        coord_vals = (2 * torch.arange(input_size) / input_size) - 1\n",
    "        xchannel = coord_vals.repeat((input_size, 1)).unsqueeze(dim=0)\n",
    "        ychannel = xchannel.permute(0, 2, 1)\n",
    "        return torch.cat((xchannel.unsqueeze(dim=0), ychannel.unsqueeze(dim=0)), dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = x.shape[0]\n",
    "        x = torch.cat((x, self.cc_xy.repeat(n, 1, 1, 1).to(self.device)), dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, device, coordconv=True):\n",
    "        super(CNN, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=1)\n",
    "        self.bn2 = nn.BatchNorm2d(2)\n",
    "        self.bn3 = nn.BatchNorm2d(2)\n",
    "        # input (N, C, H, W) is (N, 1, 64, 64)\n",
    "        if coordconv:\n",
    "            self.conv1 = CoordConv2d(device, 1, 1, kernel_size=1, padding=0, stride=1, input_size=64)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(1, 1, kernel_size=1, padding=0, stride=1)\n",
    "        self.conv2 = nn.Conv2d(1, 2, kernel_size=3, padding=1, stride=2)\n",
    "        self.conv3 = nn.Conv2d(2, 2, kernel_size=3, padding=1, stride=2)\n",
    "        self.fc1 = nn.Linear(2 * 4 * 4, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.relu(self.pool(self.bn2(self.conv2(x))))\n",
    "        x = self.relu(self.pool(self.bn3(self.conv3(x))))\n",
    "        x = self.relu(self.fc1(x.view(x.size(0), -1)))\n",
    "        return x\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "train_x, train_y, test_x, test_y = generate_data()\n",
    "train_x, train_y, test_x, test_y = train_x.to(device), train_y.to(device), test_x.to(device), test_y.to(device)\n",
    "models = [CNN(device=device, coordconv=False).to(device), CNN(device=device, coordconv=True).to(device)]\n",
    "model_names = [\"Standard\", \"CoordConv\"]\n",
    "n_epochs = 5000\n",
    "batch_size = 32\n",
    "\n",
    "loss_history = [[],[]]  # append validation losses as the models train for eventual plotting.\n",
    "\n",
    "for model_idx, model in enumerate(models):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    criterion = nn.L1Loss()\n",
    "    for epoch_i in range(n_epochs):\n",
    "        model.train()\n",
    "        # sample a batch\n",
    "        sample_idxes = np.random.randint(2352, size=(batch_size))\n",
    "        pred_y = model(train_x[sample_idxes])\n",
    "        loss = criterion(pred_y, train_y[sample_idxes])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch_i + 1) % 50 == 0:\n",
    "            # evaluate the model\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                test_loss = criterion(model(test_x), test_y)\n",
    "            print(\"Epoch: {}/{}, Model: {}, Train Loss: {:.3f}, Test Loss: {:.3f}\".format(epoch_i + 1, n_epochs, model_names[model_idx], loss.item(), test_loss.item()))\n",
    "            loss_history[model_idx].append(test_loss.item())\n",
    "\n",
    "    print(\"---\" * 10, \"\\n\")\n",
    "\n",
    "\n",
    "# plot the validation loss histories\n",
    "plt.ion()\n",
    "epoch_x = np.arange(50, n_epochs+1, 50)\n",
    "plt.plot(epoch_x, loss_history[0], label=\"Standard\", lw=3)\n",
    "plt.plot(epoch_x, loss_history[1], label=\"CoordConv\", lw=3)\n",
    "plt.legend()\n",
    "plt.title(\"Supervised Regression Error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")\n",
    "\n",
    "\n",
    "# Functions to show the CoordConv predictions on input images after training, if desired.\n",
    "def test_show(sample_idx):\n",
    "    plt.imshow(test_x[sample_idx, 0].detach().cpu().numpy(), cmap='Reds')\n",
    "    with torch.no_grad():\n",
    "        pred_y = model(test_x)[sample_idx]\n",
    "    print(\"Predicted: {}, Target: {}\".format(pred_y.detach().cpu().numpy(), test_y[sample_idx].detach().cpu().numpy()))\n",
    "\n",
    "def train_show(sample_idx):\n",
    "    plt.imshow(train_x[sample_idx, 0].detach().cpu().numpy(), cmap='Reds')\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        pred_y = model(train_x)[sample_idx]\n",
    "    print(\"Predicted: {}, Target: {}\".format(pred_y.detach().cpu().numpy(), train_y[sample_idx].detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(1,2)\n",
    "y1 = torch.randn(1,2)\n",
    "gt = torch.randn(1,2)\n",
    "catX = torch.cat([x1,y1])\n",
    "catY = torch.cat([gt,gt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_1 = loss(x1,gt)\n",
    "loss_2 = loss(y1,gt)\n",
    "\n",
    "print(loss_1)\n",
    "print(loss_2)\n",
    "\n",
    "# tensor([[0.5266, 0.1171]])\n",
    "# tensor([[0.6186, 0.3922]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_3 = loss(catX,catY)\n",
    "\n",
    "print(loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(5)\n",
    "y = np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx,yy = np.meshgrid(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xx,yy,marker=\".\",color=\"b\",linestyle=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(3)*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(3)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,v = np.meshgrid(np.arange(3)*3,np.arange(3)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = 0\n",
    "id2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1,2,3],\n",
    "                [2,5,2],\n",
    "                [1,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[id1,id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h[id1,id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array([[0,0,0],\n",
    "       [0,1,0],\n",
    "       [0,0,0],])\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "#y [1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tensor = torch.from_numpy(img)\n",
    "\n",
    "tensor = tensor.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = CoordConv2d(\"cpu\", 1, 1, kernel_size=1, padding=0, stride=1, input_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1(tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Regression with CoordConv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, device, in_channels, out_channels, kernel_size, padding, stride, input_size):\n",
    "        super(CoordConv2d, self).__init__()\n",
    "        self.device = device\n",
    "        self.cc_xy = self.make_channels(input_size)\n",
    "        self.conv = nn.Conv2d(in_channels+2, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "\n",
    "    def make_channels(self, input_size):\n",
    "        coord_vals = (2 * torch.arange(input_size) / input_size) - 1\n",
    "        \n",
    "       \n",
    "        xchannel = coord_vals.repeat((input_size, 1)).unsqueeze(dim=0)\n",
    "        ychannel = xchannel.permute(0, 2, 1)\n",
    "        return torch.cat((xchannel.unsqueeze(dim=0), ychannel.unsqueeze(dim=0)), dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = x.shape[0]\n",
    "        x = torch.cat((x, self.cc_xy.repeat(n, 1, 1, 1).to(self.device)), dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = CoordConv2d(\"cpu\", 3, 3, kernel_size=1, padding=0, stride=1, input_size=64)\n",
    "   \n",
    "            # self.conv1 = nn.Conv2d(1, 1, kernel_size=1, padding=0, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(4,3,64,64).to(device)\n",
    "\n",
    "# conv1(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# models = [CNN(device=device, coordconv=False).to(device), CNN(device=device, coordconv=True).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_Model_1 = BB_model(device,coordConv=True).to(device)\n",
    "\n",
    "regression_Model_2  = BB_model(device,coordConv=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression_Model_1(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tensor = torch.randn(4,3,64,64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_1 = nn.L1Loss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_1(pred_tensor,input_tensor).sum(1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0 \n",
    "for j,k in zip(input_tensor,pred_tensor):\n",
    "    \n",
    "    \n",
    "    total_loss += loss_1(k,j).sum(1).sum()\n",
    "    # print(loss_1(k,j).sum(1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epoch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainLossModel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLossModel1 = [68.28050513016551,\n",
    " 65.62488816913806,\n",
    " 59.81700656288549,\n",
    " 47.68163339715255,\n",
    " 23.58207727733411,\n",
    " 9.820071471364875,\n",
    " 7.343100547790527,\n",
    " 6.936299600099263,\n",
    " 6.561544142271343,\n",
    " 6.248961147509124,\n",
    " 5.921486227135909,\n",
    " 5.421173848603901,\n",
    " 4.664885972675524,\n",
    " 3.975954532623291,\n",
    " 3.5830030566767643,\n",
    " 3.2883990312877454,\n",
    " 3.0593762523249577,\n",
    " 2.8676067904422156,\n",
    " 2.7213477084511206,\n",
    " 2.547908155541671,\n",
    " 2.440237747995477,\n",
    " 2.3724605660689506,\n",
    " 2.3558950800644722,\n",
    " 2.3216646345038163,\n",
    " 2.3052869721462854,\n",
    " 2.2401248969529806,\n",
    " 2.3007123846756783,\n",
    " 2.305938858734934,\n",
    " 2.1972941411168954,\n",
    " 2.1649156746111418,\n",
    " 2.104501667775606,\n",
    " 2.1308251995789376,\n",
    " 2.084116032249049,\n",
    " 2.1654670050269678,\n",
    " 2.088952616641396,\n",
    " 2.0328448320689954,\n",
    " 2.036092237422341,\n",
    " 2.0027414372092798,\n",
    " 2.003695845603943,\n",
    " 1.9912696637605365,\n",
    " 1.9280576580449154,\n",
    " 1.9480871087626408,\n",
    " 2.0456484117006,\n",
    " 1.9850581758900692,\n",
    " 1.9068721595563387,\n",
    " 1.8830207837255377,\n",
    " 1.908837356065449,\n",
    " 1.964211476476569,\n",
    " 1.9530157540973865,\n",
    " 1.8911270405116833,\n",
    " 1.8899118461106952,\n",
    " 1.8800873066249646,\n",
    " 1.849120296930012,\n",
    " 1.8649798945376748,\n",
    " 1.8417292707844783,\n",
    " 1.8274180073487132,\n",
    " 1.8325849708757902,\n",
    " 1.8079830533579777,\n",
    " 1.8013163867749666,\n",
    " 1.8247320401041132,\n",
    " 1.80855215223212,\n",
    " 1.7555797100067139,\n",
    " 1.777278605260347,\n",
    " 1.7460961153632717,\n",
    " 1.7326714616072805,\n",
    " 1.7304664348301135,\n",
    " 1.7664734501587718,\n",
    " 1.757043951436093,\n",
    " 1.709508318650095,\n",
    " 1.7285376034284894,\n",
    " 1.6577842172823454,\n",
    " 1.6729020758679038,\n",
    " 1.7605895180451243,\n",
    " 1.7548707347167165,\n",
    " 1.7114581748058921,\n",
    " 1.6845240655698275,\n",
    " 1.7117109235964323,\n",
    " 1.7370394844757884,\n",
    " 1.714644614018892,\n",
    " 1.683782602611341,\n",
    " 1.6904316136711521,\n",
    " 1.650501433171724,\n",
    " 1.635898797135604,\n",
    " 1.6284060415468717,\n",
    " 1.6087490194722225,\n",
    " 1.6075890189722966,\n",
    " 1.601535401846233,\n",
    " 1.5595416332546033,\n",
    " 1.6115675976401882,\n",
    " 1.64955945391404,\n",
    " 1.5978446257741827,\n",
    " 1.5724606827685708,\n",
    " 1.5371948794314736,\n",
    " 1.5596598198539333,\n",
    " 1.5207288767162122,\n",
    " 1.4957340516542132,\n",
    " 1.5806434656444348,\n",
    " 1.5309730391753347,\n",
    " 1.600862415213334,\n",
    " 1.5464605657677901]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valLossModel1 =  [68.90546035766602, 61.56637477874756, 952.7806701660156, 810.3438720703125, 15.786891460418701, 13.454748392105103, 8.070767402648926, 6.924545049667358, 6.517513871192932, 6.228425979614258, 6.068917751312256, 5.536641240119934, 4.160773277282715, 3.6340972781181335, 3.5631832480430603, 3.0644643902778625, 2.78153458237648, 2.654276579618454, 2.45757132768631, 2.413040280342102, 2.308493971824646, 2.2595920860767365, 2.2240691781044006, 2.2414967119693756, 2.1230928897857666, 2.119713634252548, 2.120747923851013, 2.1427029967308044, 2.12529793381691, 2.0213115215301514, 2.0390857458114624, 2.1395826637744904, 1.9609893262386322, 2.0884757936000824, 1.9631588757038116, 1.9820888042449951, 1.914979100227356, 1.9358978867530823, 1.9396913945674896, 1.8884586691856384, 1.9031506776809692, 1.8951497077941895, 1.865460753440857, 1.876004308462143, 1.8659241199493408, 1.885868400335312, 1.8572442531585693, 1.8696589767932892, 1.8276720345020294, 1.9082961976528168, 1.85065758228302, 1.860484391450882, 1.824264407157898, 1.833799421787262, 1.9174040257930756, 1.864008367061615, 1.8715886175632477, 1.8427839279174805, 1.8189807832241058, 1.847440630197525, 1.812896192073822, 1.755580484867096, 1.760489672422409, 1.7367846369743347, 1.8441311419010162, 1.7706548273563385, 1.837672084569931, 1.7540681958198547, 1.7603263556957245, 1.7473979592323303, 1.7059321403503418, 1.7229499816894531, 1.8236200511455536, 1.9254466593265533, 1.7679736614227295, 1.7567171454429626, 1.9713301062583923, 1.7706826031208038, 1.7226713001728058, 1.7720273435115814, 1.7138517796993256, 1.7112639248371124, 1.7340607047080994, 1.6640256643295288, 1.7693849503993988, 1.690043866634369, 1.6531054079532623, 1.6595081388950348, 1.8031052947044373, 1.694405734539032, 1.700481116771698, 1.769815742969513, 1.6867660880088806, 1.6367439329624176, 1.689428985118866, 1.757577896118164, 1.707352727651596, 1.7181978821754456, 1.7547268271446228, 1.691870540380478]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "\n",
    "plt.plot(epoch_x, valLossModel2, label=\"Standard\", lw=3)\n",
    "plt.plot(epoch_x, valLossModel1, label=\"CoordConv\", lw=3)\n",
    "plt.legend()\n",
    "plt.title(\"Supervised  Validation Regression Error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LuminEye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
