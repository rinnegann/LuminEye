{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "import time \n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision import models\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model, self.path)\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, device, in_channels, out_channels, kernel_size, padding, stride, input_size):\n",
    "        super(CoordConv2d, self).__init__()\n",
    "        self.device = device\n",
    "        self.cc_xy = self.make_channels(input_size)\n",
    "        \n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels+2, out_channels,\n",
    "                              kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "\n",
    "    def make_channels(self, input_size):\n",
    "        coord_vals = (2 * torch.arange(input_size) / input_size) - 1\n",
    "\n",
    "        xchannel = coord_vals.repeat((input_size, 1)).unsqueeze(dim=0)\n",
    "\n",
    "        ychannel = xchannel.permute(0, 2, 1)\n",
    "       \n",
    "        return torch.cat((xchannel.unsqueeze(dim=0), ychannel.unsqueeze(dim=0)), dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = x.shape[0]\n",
    "        x = torch.cat((x, self.cc_xy.repeat(\n",
    "            n, 1, 1, 1).to(self.device)), dim=1)\n",
    "        # print(x.shape)\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnsr = torch.randn(1,3,64,64).to(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1785,  0.3138, -0.4360,  ..., -0.3012, -0.6155, -0.6289],\n",
       "          [-0.0556,  1.0200, -0.9818,  ..., -1.5593, -0.0838, -0.2889],\n",
       "          [-1.1673, -0.2957, -1.1777,  ...,  0.2591, -0.0233, -0.6991],\n",
       "          ...,\n",
       "          [ 1.0910,  0.0368,  2.0610,  ..., -0.6453,  0.4333,  0.4999],\n",
       "          [ 0.7932,  0.1828,  1.7340,  ...,  1.3742,  1.0697, -0.2658],\n",
       "          [ 0.5036,  0.5288,  1.5669,  ...,  0.4458, -0.2962, -0.3131]],\n",
       "\n",
       "         [[-0.1653,  0.1986, -0.4446,  ..., -0.4741, -0.6683, -0.6018],\n",
       "          [-0.3045,  0.2005, -0.7104,  ..., -0.8084, -0.3837, -0.4564],\n",
       "          [-0.7224, -0.3058, -0.6566,  ..., -0.0677, -0.3357, -0.6472],\n",
       "          ...,\n",
       "          [ 0.9823,  0.4334,  1.5024,  ..., -0.0805,  0.3947,  0.3991],\n",
       "          [ 0.7217,  0.4440,  1.0401,  ...,  0.7732,  0.5252,  0.1168],\n",
       "          [ 0.7290,  0.2872,  0.8995,  ...,  0.6123,  0.2208,  0.1484]],\n",
       "\n",
       "         [[ 0.2845,  0.9853, -0.1861,  ...,  0.3106,  0.3239,  0.5892],\n",
       "          [-0.0420,  0.1271, -0.1656,  ...,  1.0436,  0.1184,  0.5834],\n",
       "          [-0.0168,  0.2819,  0.3358,  ...,  0.7418,  0.1165,  0.7553],\n",
       "          ...,\n",
       "          [-0.3994, -0.1419,  0.5802,  ..., -0.3124, -0.3078, -0.2937],\n",
       "          [-0.3827, -0.4776, -0.5193,  ..., -0.4401, -0.3243, -0.0888],\n",
       "          [-0.2040, -1.3369, -0.9492,  ...,  0.3572,  0.1242, -0.0326]]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = CoordConv2d(\n",
    "                \"cpu\", 3, 3, kernel_size=1, padding=0, stride=1, input_size=64)\n",
    "\n",
    "conv1(tnsr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nipun/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_impl',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_make_layer',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_norm_layer',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'avgpool',\n",
       " 'base_width',\n",
       " 'bfloat16',\n",
       " 'bn1',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'conv1',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'dilation',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fc',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'groups',\n",
       " 'half',\n",
       " 'inplanes',\n",
       " 'ipu',\n",
       " 'layer1',\n",
       " 'layer2',\n",
       " 'layer3',\n",
       " 'layer4',\n",
       " 'load_state_dict',\n",
       " 'maxpool',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'relu',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet34(weights=True)\n",
    "layers = list(resnet.children())[:8]\n",
    "features1 = nn.Sequential(*layers[:6])\n",
    "\n",
    "\n",
    "\n",
    "dir(resnet)\n",
    "        # # for param in resnet.parameters():\n",
    "\n",
    "        # #     param.requires_grad = False\n",
    "\n",
    "        # layers = list(resnet.children())[:8]\n",
    "        # self.\n",
    "        # self.features2 = nn.Sequential(*layers[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1(tnsr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(3, 3, kernel_size=1, padding=0, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BB_model(nn.Module):\n",
    "    def __init__(self, device, coordConv=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if coordConv:\n",
    "            self.conv1 = CoordConv2d(\n",
    "                device, 3, 3, kernel_size=1, padding=0, stride=1, input_size=64)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 3, kernel_size=1, padding=0, stride=1)\n",
    "\n",
    "        resnet = models.resnet34(weights=True)\n",
    "\n",
    "        # for param in resnet.parameters():\n",
    "\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "\n",
    "        # self.fc2\n",
    "        self.bb = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.features1(x)  # 1, 128, 32, 32\n",
    "\n",
    "        x = self.features2(x)  # [1, 512, 8, 8]\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)  # [ 1,512,1,1]\n",
    "\n",
    "        x = x.view(x.shape[0], -1)  # [1, 512]\n",
    "\n",
    "        return self.bb(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_DIR = \"/home/nipun/Videos/Center_Regression/Mix_Iris_Center_Gi42_BioId_H2HEAD/Images\"\n",
    "trn_df = pd.read_csv(\"/home/nipun/Videos/Center_Regression/Mix_Iris_Center_Gi42_BioId_H2HEAD/mix_train.csv\")\n",
    "val_df = pd.read_csv(\"/home/nipun/Videos/Center_Regression/Mix_Iris_Center_Gi42_BioId_H2HEAD/mix_val.csv\")\n",
    "RESIZE_AMT = 64\n",
    "BACTH_SIZE = 512\n",
    "\n",
    "train_transforms =  A.Compose([\n",
    "    A.Resize(width=RESIZE_AMT,height=RESIZE_AMT),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(p=1)\n",
    "])\n",
    "\n",
    "val_transforms =  A.Compose([\n",
    "    A.Resize(width=RESIZE_AMT,height=RESIZE_AMT),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(p=1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CenterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df,image_dir=IMAGE_DIR,transforms=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df\n",
    "        self.image_ids = df.Image_Name.unique()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self,ix):\n",
    "        \n",
    "        img_id = self.image_ids[ix]\n",
    "        img_path = os.path.join(self.image_dir,img_id)\n",
    "        \n",
    "        img = cv2.imread(img_path)[:,:,::-1]\n",
    "        \n",
    "        data = self.df[self.df[\"Image_Name\"]==img_id]\n",
    "        \n",
    "        \n",
    "        x1 = data[\"X1\"].values[0] * RESIZE_AMT\n",
    "        y1 = data[\"Y1\"].values[0] * RESIZE_AMT\n",
    "        \n",
    "        center_loc = torch.Tensor([x1,y1]).float()\n",
    "\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=img)\n",
    "            \n",
    "            image = transformed[\"image\"]\n",
    "            \n",
    "    \n",
    "        return image,center_loc\n",
    "    def collate_fn(self,batch):\n",
    "        return tuple(zip(*batch))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CenterDataset(trn_df,transforms=train_transforms)\n",
    "test_ds = CenterDataset(val_df,transforms=val_transforms)\n",
    "\n",
    "trainLoader = DataLoader(train_ds, batch_size=BACTH_SIZE,\n",
    "\tshuffle=True, num_workers=os.cpu_count(), pin_memory=True,drop_last=True)\n",
    "testLoader = DataLoader(test_ds, batch_size=BACTH_SIZE,\n",
    "\tnum_workers=os.cpu_count(), pin_memory=True,drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main_training(model,patience, optimizer,scheduler, train_dl, test_dl, epochs,loss_fn):\n",
    "    \n",
    "    \n",
    "    \n",
    "    idx = 0\n",
    "\n",
    "    prev_loss = 0\n",
    "    \n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    epochTrainLoss = []\n",
    "    epochValLoss = []\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "\n",
    "        for x, y_bb in train_dl:\n",
    "            batch = x.shape[0]\n",
    "            x = x.cuda().float()\n",
    "\n",
    "            y_bb = y_bb.cuda()\n",
    "\n",
    "            \n",
    "    \n",
    "            out_bb = model(x)\n",
    "\n",
    "            loss_bb = loss_fn(out_bb,y_bb).sum(1)\n",
    "            # loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "            loss_bb = loss_bb.sum()\n",
    "\n",
    "            loss = loss_bb\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "            total += batch\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "        val_loss = val_epochs(model, test_dl,loss_fn)\n",
    "\n",
    "        \n",
    "        early_stopping(val_loss,model)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # if i == 0:\n",
    "        #     prev_loss = val_loss\n",
    "        # if val_loss < prev_loss:\n",
    "        #     prev_loss = val_loss\n",
    "\n",
    "        #     model_name = f\"Regression_model_{str(prev_loss)}.pth\"\n",
    "        #     torch.save(model, model_name)\n",
    "\n",
    "        train_loss = sum_loss/total\n",
    "        epochTrainLoss.append(train_loss)\n",
    "        epochValLoss.append(val_loss)\n",
    "        \n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        # train_metrics = {\"train/epoch\": i+1, \"train/train_loss\": train_loss}\n",
    "\n",
    "        # val_metrics = {\"val/epoch\": i+1, \"val/val_loss\": val_loss}\n",
    "        # wandb.log({**train_metrics, **val_metrics})\n",
    "\n",
    "        print(f\"Epoch Number {i+1}\")\n",
    "        print(\"train_loss %.3f \" % (train_loss))\n",
    "        print(\"Validation Loss %.3f \" % (val_loss))\n",
    "        print(\"*\"*8)\n",
    "    \n",
    "    return epochTrainLoss,epochValLoss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epochs(model,val_loader,loss_fn):\n",
    "    \n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total = 0\n",
    "    for x,y_bb in val_loader:\n",
    "        \n",
    "    \n",
    "        x = x.cuda().float()\n",
    "        y_bb = y_bb.cuda()\n",
    "        \n",
    "        out_bb = model(x)\n",
    "        \n",
    "        total += x.shape[0]\n",
    "        with torch.no_grad():\n",
    "            # loss_bb = F.l1_loss(out_bb,y_bb,reduction='none').sum(1)\n",
    "            loss_bb = loss_fn(out_bb,y_bb).sum(1)\n",
    "            loss_bb = loss_bb.sum()\n",
    "            \n",
    "            total_val_loss += loss_bb.item()\n",
    "            \n",
    "    return total_val_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nipun/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 63.049801).  Saving model ...\n",
      "Epoch Number 1\n",
      "train_loss 62.981 \n",
      "Validation Loss 63.050 \n",
      "********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nipun/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 2\n",
      "train_loss 60.497 \n",
      "Validation Loss 563.215 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 3\n",
      "train_loss 55.054 \n",
      "Validation Loss 143.363 \n",
      "********\n",
      "Validation loss decreased (63.049801 --> 40.486172).  Saving model ...\n",
      "Epoch Number 4\n",
      "train_loss 46.565 \n",
      "Validation Loss 40.486 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 5\n",
      "train_loss 32.779 \n",
      "Validation Loss 53.963 \n",
      "********\n",
      "Validation loss decreased (40.486172 --> 34.723103).  Saving model ...\n",
      "Epoch Number 6\n",
      "train_loss 16.773 \n",
      "Validation Loss 34.723 \n",
      "********\n",
      "Validation loss decreased (34.723103 --> 9.169888).  Saving model ...\n",
      "Epoch Number 7\n",
      "train_loss 9.429 \n",
      "Validation Loss 9.170 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 8\n",
      "train_loss 8.020 \n",
      "Validation Loss 9.359 \n",
      "********\n",
      "Validation loss decreased (9.169888 --> 8.580801).  Saving model ...\n",
      "Epoch Number 9\n",
      "train_loss 7.753 \n",
      "Validation Loss 8.581 \n",
      "********\n",
      "Validation loss decreased (8.580801 --> 7.413427).  Saving model ...\n",
      "Epoch Number 10\n",
      "train_loss 7.492 \n",
      "Validation Loss 7.413 \n",
      "********\n",
      "Validation loss decreased (7.413427 --> 6.901305).  Saving model ...\n",
      "Epoch Number 11\n",
      "train_loss 7.195 \n",
      "Validation Loss 6.901 \n",
      "********\n",
      "Validation loss decreased (6.901305 --> 6.173456).  Saving model ...\n",
      "Epoch Number 12\n",
      "train_loss 6.841 \n",
      "Validation Loss 6.173 \n",
      "********\n",
      "Validation loss decreased (6.173456 --> 5.874841).  Saving model ...\n",
      "Epoch Number 13\n",
      "train_loss 6.557 \n",
      "Validation Loss 5.875 \n",
      "********\n",
      "Validation loss decreased (5.874841 --> 5.610347).  Saving model ...\n",
      "Epoch Number 14\n",
      "train_loss 6.327 \n",
      "Validation Loss 5.610 \n",
      "********\n",
      "Validation loss decreased (5.610347 --> 5.377815).  Saving model ...\n",
      "Epoch Number 15\n",
      "train_loss 6.147 \n",
      "Validation Loss 5.378 \n",
      "********\n",
      "Validation loss decreased (5.377815 --> 5.080941).  Saving model ...\n",
      "Epoch Number 16\n",
      "train_loss 5.911 \n",
      "Validation Loss 5.081 \n",
      "********\n",
      "Validation loss decreased (5.080941 --> 4.800994).  Saving model ...\n",
      "Epoch Number 17\n",
      "train_loss 5.694 \n",
      "Validation Loss 4.801 \n",
      "********\n",
      "Validation loss decreased (4.800994 --> 4.482988).  Saving model ...\n",
      "Epoch Number 18\n",
      "train_loss 5.557 \n",
      "Validation Loss 4.483 \n",
      "********\n",
      "Validation loss decreased (4.482988 --> 4.253893).  Saving model ...\n",
      "Epoch Number 19\n",
      "train_loss 5.336 \n",
      "Validation Loss 4.254 \n",
      "********\n",
      "Validation loss decreased (4.253893 --> 3.984182).  Saving model ...\n",
      "Epoch Number 20\n",
      "train_loss 5.144 \n",
      "Validation Loss 3.984 \n",
      "********\n",
      "Validation loss decreased (3.984182 --> 3.810291).  Saving model ...\n",
      "Epoch Number 21\n",
      "train_loss 4.927 \n",
      "Validation Loss 3.810 \n",
      "********\n",
      "Validation loss decreased (3.810291 --> 3.801782).  Saving model ...\n",
      "Epoch Number 22\n",
      "train_loss 4.785 \n",
      "Validation Loss 3.802 \n",
      "********\n",
      "Validation loss decreased (3.801782 --> 3.620092).  Saving model ...\n",
      "Epoch Number 23\n",
      "train_loss 4.691 \n",
      "Validation Loss 3.620 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 24\n",
      "train_loss 4.675 \n",
      "Validation Loss 3.684 \n",
      "********\n",
      "Validation loss decreased (3.620092 --> 3.492778).  Saving model ...\n",
      "Epoch Number 25\n",
      "train_loss 4.502 \n",
      "Validation Loss 3.493 \n",
      "********\n",
      "Validation loss decreased (3.492778 --> 3.491474).  Saving model ...\n",
      "Epoch Number 26\n",
      "train_loss 4.462 \n",
      "Validation Loss 3.491 \n",
      "********\n",
      "Validation loss decreased (3.491474 --> 3.430659).  Saving model ...\n",
      "Epoch Number 27\n",
      "train_loss 4.344 \n",
      "Validation Loss 3.431 \n",
      "********\n",
      "Validation loss decreased (3.430659 --> 3.319761).  Saving model ...\n",
      "Epoch Number 28\n",
      "train_loss 4.285 \n",
      "Validation Loss 3.320 \n",
      "********\n",
      "Validation loss decreased (3.319761 --> 3.288775).  Saving model ...\n",
      "Epoch Number 29\n",
      "train_loss 4.254 \n",
      "Validation Loss 3.289 \n",
      "********\n",
      "Validation loss decreased (3.288775 --> 3.197704).  Saving model ...\n",
      "Epoch Number 30\n",
      "train_loss 4.194 \n",
      "Validation Loss 3.198 \n",
      "********\n",
      "Validation loss decreased (3.197704 --> 3.116550).  Saving model ...\n",
      "Epoch Number 31\n",
      "train_loss 4.138 \n",
      "Validation Loss 3.117 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 32\n",
      "train_loss 4.129 \n",
      "Validation Loss 3.117 \n",
      "********\n",
      "Validation loss decreased (3.116550 --> 2.977272).  Saving model ...\n",
      "Epoch Number 33\n",
      "train_loss 4.089 \n",
      "Validation Loss 2.977 \n",
      "********\n",
      "Validation loss decreased (2.977272 --> 2.909247).  Saving model ...\n",
      "Epoch Number 34\n",
      "train_loss 4.061 \n",
      "Validation Loss 2.909 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 35\n",
      "train_loss 4.003 \n",
      "Validation Loss 2.991 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 36\n",
      "train_loss 4.143 \n",
      "Validation Loss 2.992 \n",
      "********\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch Number 37\n",
      "train_loss 4.143 \n",
      "Validation Loss 3.171 \n",
      "********\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch Number 38\n",
      "train_loss 4.062 \n",
      "Validation Loss 2.912 \n",
      "********\n",
      "Validation loss decreased (2.909247 --> 2.867296).  Saving model ...\n",
      "Epoch Number 39\n",
      "train_loss 4.000 \n",
      "Validation Loss 2.867 \n",
      "********\n",
      "Validation loss decreased (2.867296 --> 2.818288).  Saving model ...\n",
      "Epoch Number 40\n",
      "train_loss 3.842 \n",
      "Validation Loss 2.818 \n",
      "********\n",
      "Validation loss decreased (2.818288 --> 2.671290).  Saving model ...\n",
      "Epoch Number 41\n",
      "train_loss 3.857 \n",
      "Validation Loss 2.671 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 42\n",
      "train_loss 3.825 \n",
      "Validation Loss 2.697 \n",
      "********\n",
      "Validation loss decreased (2.671290 --> 2.628469).  Saving model ...\n",
      "Epoch Number 43\n",
      "train_loss 3.770 \n",
      "Validation Loss 2.628 \n",
      "********\n",
      "Validation loss decreased (2.628469 --> 2.615873).  Saving model ...\n",
      "Epoch Number 44\n",
      "train_loss 3.776 \n",
      "Validation Loss 2.616 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 45\n",
      "train_loss 3.769 \n",
      "Validation Loss 2.654 \n",
      "********\n",
      "Validation loss decreased (2.615873 --> 2.612935).  Saving model ...\n",
      "Epoch Number 46\n",
      "train_loss 3.746 \n",
      "Validation Loss 2.613 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 47\n",
      "train_loss 3.804 \n",
      "Validation Loss 2.690 \n",
      "********\n",
      "Validation loss decreased (2.612935 --> 2.571359).  Saving model ...\n",
      "Epoch Number 48\n",
      "train_loss 3.809 \n",
      "Validation Loss 2.571 \n",
      "********\n",
      "Validation loss decreased (2.571359 --> 2.463686).  Saving model ...\n",
      "Epoch Number 49\n",
      "train_loss 3.729 \n",
      "Validation Loss 2.464 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 50\n",
      "train_loss 3.667 \n",
      "Validation Loss 2.510 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 51\n",
      "train_loss 3.703 \n",
      "Validation Loss 2.493 \n",
      "********\n",
      "Validation loss decreased (2.463686 --> 2.402192).  Saving model ...\n",
      "Epoch Number 52\n",
      "train_loss 3.648 \n",
      "Validation Loss 2.402 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 53\n",
      "train_loss 3.561 \n",
      "Validation Loss 2.465 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 54\n",
      "train_loss 3.593 \n",
      "Validation Loss 2.463 \n",
      "********\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch Number 55\n",
      "train_loss 3.556 \n",
      "Validation Loss 2.445 \n",
      "********\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch Number 56\n",
      "train_loss 3.636 \n",
      "Validation Loss 2.469 \n",
      "********\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m update_optimizer(optimizer, \u001b[39m0.001\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mOneCycleLR(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     optimizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m0.006\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     n_epoch,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_ds)\u001b[39m/\u001b[39m\u001b[39m/\u001b[39mBACTH_SIZE\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m trainLossModel2,valLossModel2\u001b[39m=\u001b[39mmain_training(model\u001b[39m=\u001b[39;49mmodel,patience\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m,optimizer\u001b[39m=\u001b[39;49moptimizer,scheduler\u001b[39m=\u001b[39;49mscheduler,train_dl\u001b[39m=\u001b[39;49mtrainLoader,test_dl\u001b[39m=\u001b[39;49mtestLoader,epochs\u001b[39m=\u001b[39;49mn_epoch,loss_fn\u001b[39m=\u001b[39;49mloss_fn)\n",
      "\u001b[1;32m/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb Cell 15\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/nipun/Documents/Uni_Malta/LuminEye/LuminEye-Iris-Center-Localization/coordconv_regression.ipynb#X20sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    158\u001b[0m          grads,\n\u001b[1;32m    159\u001b[0m          exp_avgs,\n\u001b[1;32m    160\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    162\u001b[0m          state_steps,\n\u001b[1;32m    163\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    164\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    165\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    166\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    167\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    168\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    169\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    170\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m func(params,\n\u001b[1;32m    214\u001b[0m      grads,\n\u001b[1;32m    215\u001b[0m      exp_avgs,\n\u001b[1;32m    216\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    217\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    218\u001b[0m      state_steps,\n\u001b[1;32m    219\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    220\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    221\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    222\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    224\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    225\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    226\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:263\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    262\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[0;32m--> 263\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39;49maddcmul_(grad, grad\u001b[39m.\u001b[39;49mconj(), value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta2)\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m capturable:\n\u001b[1;32m    266\u001b[0m     step \u001b[39m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "    \n",
    "loss_fn = nn.L1Loss(reduction='none')\n",
    "\n",
    "model = BB_model(device,coordConv=False).to(device)\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.006)\n",
    "    \n",
    "update_optimizer(optimizer, 0.001)\n",
    "    \n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    0.006,\n",
    "    n_epoch,\n",
    "    steps_per_epoch=len(train_ds)//BACTH_SIZE\n",
    ")\n",
    "\n",
    "    \n",
    "trainLossModel2,valLossModel2=main_training(model=model,patience=7,optimizer=optimizer,scheduler=scheduler,train_dl=trainLoader,test_dl=testLoader,epochs=n_epoch,loss_fn=loss_fn)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLossModel1 = trainLossModel2\n",
    "trainLossModel1 = trainLossModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_x = np.arange(0, n_epoch, 1)\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "plt.plot(epoch_x, trainLossModel2, label=\"Standard\", lw=3)\n",
    "plt.plot(epoch_x, trainLossModel1, label=\"CoordConv\", lw=3)\n",
    "plt.legend()\n",
    "plt.title(\"Supervised Training Regression Error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [[1.,2.],\n",
    "      [2.,3.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = [[4.,4.],\n",
    "      [4.,5.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2142791932.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [12], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    [2,2]]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "[3,2],\n",
    "[2,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.L1Loss(reduction='none')\n",
    "l2 = nn.L1Loss(reduction='mean')\n",
    "l3 = nn.L1Loss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(x1)\n",
    "x2 = torch.tensor(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1(x2,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 4.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1(x2,x1).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1(x2,x1).sum(1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2500)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2(x2,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3(x2,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# torch.log  and math.log is e based\n",
    "class WingLoss(nn.Module):\n",
    "    def __init__(self, omega=10, epsilon=2):\n",
    "        super(WingLoss, self).__init__()\n",
    "        self.omega = omega\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        y = target\n",
    "        y_hat = pred\n",
    "        delta_y = (y - y_hat).abs()\n",
    "        delta_y1 = delta_y[delta_y < self.omega]\n",
    "        delta_y2 = delta_y[delta_y >= self.omega]\n",
    "        loss1 = self.omega * torch.log(1 + delta_y1 / self.epsilon)\n",
    "        C = self.omega - self.omega * math.log(1 + self.omega / self.epsilon)\n",
    "        loss2 = delta_y2 - C\n",
    "        return (loss1.sum() + loss2.sum()) / (len(loss1) + len(loss2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wingLoss = WingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.4893)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wingLoss(x2,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LuminEye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
