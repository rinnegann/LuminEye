{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "import time \n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision import models\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, device, in_channels, out_channels, kernel_size, padding, stride, input_size):\n",
    "        super(CoordConv2d, self).__init__()\n",
    "        self.device = device\n",
    "        self.cc_xy = self.make_channels(input_size)\n",
    "        \n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels+2, out_channels,\n",
    "                              kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "\n",
    "    def make_channels(self, input_size):\n",
    "        coord_vals = (2 * torch.arange(input_size) / input_size) - 1\n",
    "\n",
    "        xchannel = coord_vals.repeat((input_size, 1)).unsqueeze(dim=0)\n",
    "\n",
    "        ychannel = xchannel.permute(0, 2, 1)\n",
    "       \n",
    "        return torch.cat((xchannel.unsqueeze(dim=0), ychannel.unsqueeze(dim=0)), dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n = x.shape[0]\n",
    "        x = torch.cat((x, self.cc_xy.repeat(\n",
    "            n, 1, 1, 1).to(self.device)), dim=1)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "        # print(x.shape)\n",
    "        # return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnsr = torch.randn(1,3,64,64).to(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.6021,  0.0588, -0.4799,  ...,  0.4729, -0.0953,  2.6316],\n",
       "          [-1.8634,  0.9666, -1.3063,  ...,  0.1334,  0.4021, -0.2607],\n",
       "          [ 0.5176, -0.8686, -0.8241,  ..., -1.2581,  0.9498, -0.3039],\n",
       "          ...,\n",
       "          [ 0.0531, -0.8217, -1.1069,  ..., -0.8360,  0.0057, -0.7618],\n",
       "          [ 0.1394,  0.9175,  0.7420,  ...,  2.1492, -1.4799,  1.2590],\n",
       "          [-1.2697,  2.0625,  0.5092,  ..., -0.5785, -1.5654,  0.5615]],\n",
       "\n",
       "         [[-0.2325, -0.7557,  0.0101,  ...,  0.2498,  0.8970, -0.0193],\n",
       "          [-0.8498,  1.2583, -2.1959,  ...,  0.7069,  1.7374, -0.1471],\n",
       "          [-0.6616,  0.5512, -1.2373,  ..., -0.8073, -1.0099,  0.2612],\n",
       "          ...,\n",
       "          [-0.0144, -0.0542, -0.8541,  ...,  0.0389,  1.6865, -0.8222],\n",
       "          [-1.5665,  0.1591,  0.3424,  ...,  1.1934, -1.0794,  0.3710],\n",
       "          [-0.1498,  0.5400, -0.3635,  ..., -1.0015, -0.1113, -0.2157]],\n",
       "\n",
       "         [[-0.9845, -0.6154,  1.2181,  ..., -0.9560,  1.6290,  0.3202],\n",
       "          [-0.3752, -0.2539,  0.4321,  ...,  0.8840,  1.7265,  0.2958],\n",
       "          [-0.4964,  1.2171, -0.5506,  ..., -0.8654, -0.4021, -0.2670],\n",
       "          ...,\n",
       "          [ 1.1917, -0.3107, -0.7556,  ...,  1.0554, -1.8817,  0.0698],\n",
       "          [-0.0033, -1.2049,  0.7531,  ..., -0.8654,  0.3019,  1.1183],\n",
       "          [ 0.8008,  0.3122,  1.0615,  ..., -0.2431, -1.2106,  1.1457]],\n",
       "\n",
       "         [[-1.0000, -0.9688, -0.9375,  ...,  0.9062,  0.9375,  0.9688],\n",
       "          [-1.0000, -0.9688, -0.9375,  ...,  0.9062,  0.9375,  0.9688],\n",
       "          [-1.0000, -0.9688, -0.9375,  ...,  0.9062,  0.9375,  0.9688],\n",
       "          ...,\n",
       "          [-1.0000, -0.9688, -0.9375,  ...,  0.9062,  0.9375,  0.9688],\n",
       "          [-1.0000, -0.9688, -0.9375,  ...,  0.9062,  0.9375,  0.9688],\n",
       "          [-1.0000, -0.9688, -0.9375,  ...,  0.9062,  0.9375,  0.9688]],\n",
       "\n",
       "         [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-0.9688, -0.9688, -0.9688,  ..., -0.9688, -0.9688, -0.9688],\n",
       "          [-0.9375, -0.9375, -0.9375,  ..., -0.9375, -0.9375, -0.9375],\n",
       "          ...,\n",
       "          [ 0.9062,  0.9062,  0.9062,  ...,  0.9062,  0.9062,  0.9062],\n",
       "          [ 0.9375,  0.9375,  0.9375,  ...,  0.9375,  0.9375,  0.9375],\n",
       "          [ 0.9688,  0.9688,  0.9688,  ...,  0.9688,  0.9688,  0.9688]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = CoordConv2d(\n",
    "                \"cpu\", 3, 3, kernel_size=1, padding=0, stride=1, input_size=64)\n",
    "\n",
    "conv1(tnsr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nipun/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_impl',\n",
       " '_forward_pre_hooks',\n",
       " '_get_backward_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_make_layer',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_norm_layer',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'avgpool',\n",
       " 'base_width',\n",
       " 'bfloat16',\n",
       " 'bn1',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'conv1',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'dilation',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fc',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'groups',\n",
       " 'half',\n",
       " 'inplanes',\n",
       " 'ipu',\n",
       " 'layer1',\n",
       " 'layer2',\n",
       " 'layer3',\n",
       " 'layer4',\n",
       " 'load_state_dict',\n",
       " 'maxpool',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'relu',\n",
       " 'requires_grad_',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet34(weights=True)\n",
    "layers = list(resnet.children())[:8]\n",
    "features1 = nn.Sequential(*layers[:6])\n",
    "\n",
    "\n",
    "\n",
    "dir(resnet)\n",
    "        # # for param in resnet.parameters():\n",
    "\n",
    "        # #     param.requires_grad = False\n",
    "\n",
    "        # layers = list(resnet.children())[:8]\n",
    "        # self.\n",
    "        # self.features2 = nn.Sequential(*layers[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 8, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1(tnsr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(3, 3, kernel_size=1, padding=0, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BB_model(nn.Module):\n",
    "    def __init__(self, device, coordConv=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if coordConv:\n",
    "            self.conv1 = CoordConv2d(\n",
    "                device, 3, 3, kernel_size=1, padding=0, stride=1, input_size=64)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(3, 3, kernel_size=1, padding=0, stride=1)\n",
    "\n",
    "        resnet = models.resnet34(weights=True)\n",
    "\n",
    "        # for param in resnet.parameters():\n",
    "\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.features1 = nn.Sequential(*layers[:6])\n",
    "        self.features2 = nn.Sequential(*layers[6:])\n",
    "\n",
    "        # self.fc2\n",
    "        self.bb = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.features1(x)  # 1, 128, 32, 32\n",
    "\n",
    "        x = self.features2(x)  # [1, 512, 8, 8]\n",
    "\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = nn.AdaptiveAvgPool2d((1, 1))(x)  # [ 1,512,1,1]\n",
    "\n",
    "        x = x.view(x.shape[0], -1)  # [1, 512]\n",
    "\n",
    "        return self.bb(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"/home/nipun/Documents/Uni_Malta/Datasets/CenterRegression/MixDataset/images\"\n",
    "trn_df = pd.read_csv(\"/home/nipun/Documents/Uni_Malta/Datasets/CenterRegression/MixDataset/trainAll.csv\")\n",
    "val_df = pd.read_csv(\"/home/nipun/Documents/Uni_Malta/Datasets/CenterRegression/MixDataset/valAll.csv\")\n",
    "\n",
    "RESIZE_AMT = 64\n",
    "BACTH_SIZE = 512\n",
    "\n",
    "train_transforms =  A.Compose([\n",
    "    A.Resize(width=RESIZE_AMT,height=RESIZE_AMT),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(p=1)\n",
    "])\n",
    "\n",
    "val_transforms =  A.Compose([\n",
    "    A.Resize(width=RESIZE_AMT,height=RESIZE_AMT),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(p=1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CenterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df,image_dir=IMAGE_DIR,transforms=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df\n",
    "        self.image_ids = df.Image_Name.unique()\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self,ix):\n",
    "        \n",
    "        img_id = self.image_ids[ix]\n",
    "        img_path = os.path.join(self.image_dir,img_id)\n",
    "        \n",
    "        img = cv2.imread(img_path)[:,:,::-1]\n",
    "        \n",
    "        data = self.df[self.df[\"Image_Name\"]==img_id]\n",
    "        \n",
    "        \n",
    "        x1 = data[\"X1\"].values[0] * RESIZE_AMT\n",
    "        y1 = data[\"Y1\"].values[0] * RESIZE_AMT\n",
    "        \n",
    "        center_loc = torch.Tensor([x1,y1]).float()\n",
    "\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=img)\n",
    "            \n",
    "            image = transformed[\"image\"]\n",
    "            \n",
    "    \n",
    "        return image,center_loc\n",
    "    def collate_fn(self,batch):\n",
    "        return tuple(zip(*batch))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CenterDataset(trn_df,transforms=train_transforms)\n",
    "test_ds = CenterDataset(val_df,transforms=val_transforms)\n",
    "\n",
    "trainLoader = DataLoader(train_ds, batch_size=BACTH_SIZE,\n",
    "\tshuffle=True, num_workers=os.cpu_count(), pin_memory=True,drop_last=True)\n",
    "testLoader = DataLoader(test_ds, batch_size=BACTH_SIZE,\n",
    "\tnum_workers=os.cpu_count(), pin_memory=True,drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "def update_optimizer(optimizer, lr):\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main_training(model,patience, optimizer,scheduler, train_dl, test_dl, epochs,loss_fn):\n",
    "    \n",
    "    \n",
    "    \n",
    "    idx = 0\n",
    "\n",
    "    prev_loss = 0\n",
    "    \n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    epochTrainLoss = []\n",
    "    epochValLoss = []\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "\n",
    "        for x, y_bb in train_dl:\n",
    "            batch = x.shape[0]\n",
    "            x = x.cuda().float()\n",
    "\n",
    "            y_bb = y_bb.cuda()\n",
    "\n",
    "            \n",
    "    \n",
    "            out_bb = model(x)\n",
    "\n",
    "            loss_bb = loss_fn(out_bb,y_bb).sum(1)\n",
    "            # loss_bb = F.l1_loss(out_bb, y_bb, reduction=\"none\").sum(1)\n",
    "            loss_bb = loss_bb.sum()\n",
    "\n",
    "            loss = loss_bb\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "            total += batch\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "        val_loss = val_epochs(model, test_dl,loss_fn)\n",
    "\n",
    "        \n",
    "        early_stopping(val_loss,model)\n",
    "        # if i == 0:\n",
    "        #     prev_loss = val_loss\n",
    "        # if val_loss < prev_loss:\n",
    "        #     prev_loss = val_loss\n",
    "\n",
    "        #     model_name = f\"Regression_model_{str(prev_loss)}.pth\"\n",
    "        #     torch.save(model, model_name)\n",
    "\n",
    "        train_loss = sum_loss/total\n",
    "        epochTrainLoss.append(train_loss)\n",
    "        epochValLoss.append(val_loss)\n",
    "        \n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        # train_metrics = {\"train/epoch\": i+1, \"train/train_loss\": train_loss}\n",
    "\n",
    "        # val_metrics = {\"val/epoch\": i+1, \"val/val_loss\": val_loss}\n",
    "        # wandb.log({**train_metrics, **val_metrics})\n",
    "\n",
    "        print(f\"Epoch Number {i+1}\")\n",
    "        print(\"train_loss %.3f \" % (train_loss))\n",
    "        print(\"Validation Loss %.3f \" % (val_loss))\n",
    "        print(\"*\"*8)\n",
    "    \n",
    "    return epochTrainLoss,epochValLoss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epochs(model,val_loader,loss_fn):\n",
    "    \n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    total = 0\n",
    "    for x,y_bb in val_loader:\n",
    "        \n",
    "    \n",
    "        x = x.cuda().float()\n",
    "        y_bb = y_bb.cuda()\n",
    "        \n",
    "        out_bb = model(x)\n",
    "        \n",
    "        total += x.shape[0]\n",
    "        with torch.no_grad():\n",
    "            # loss_bb = F.l1_loss(out_bb,y_bb,reduction='none').sum(1)\n",
    "            loss_bb = loss_fn(out_bb,y_bb).sum(1)\n",
    "            loss_bb = loss_bb.sum()\n",
    "            \n",
    "            total_val_loss += loss_bb.item()\n",
    "            \n",
    "    return total_val_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nipun/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 67.712368).  Saving model ...\n",
      "Epoch Number 1\n",
      "train_loss 68.779 \n",
      "Validation Loss 67.712 \n",
      "********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nipun/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (67.712368 --> 60.117210).  Saving model ...\n",
      "Epoch Number 2\n",
      "train_loss 66.172 \n",
      "Validation Loss 60.117 \n",
      "********\n",
      "Validation loss decreased (60.117210 --> 53.810474).  Saving model ...\n",
      "Epoch Number 3\n",
      "train_loss 59.850 \n",
      "Validation Loss 53.810 \n",
      "********\n",
      "Validation loss decreased (53.810474 --> 44.303318).  Saving model ...\n",
      "Epoch Number 4\n",
      "train_loss 49.114 \n",
      "Validation Loss 44.303 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 5\n",
      "train_loss 28.240 \n",
      "Validation Loss 58.740 \n",
      "********\n",
      "Validation loss decreased (44.303318 --> 19.815474).  Saving model ...\n",
      "Epoch Number 6\n",
      "train_loss 11.672 \n",
      "Validation Loss 19.815 \n",
      "********\n",
      "Validation loss decreased (19.815474 --> 11.071307).  Saving model ...\n",
      "Epoch Number 7\n",
      "train_loss 9.530 \n",
      "Validation Loss 11.071 \n",
      "********\n",
      "Validation loss decreased (11.071307 --> 7.861758).  Saving model ...\n",
      "Epoch Number 8\n",
      "train_loss 9.172 \n",
      "Validation Loss 7.862 \n",
      "********\n",
      "Validation loss decreased (7.861758 --> 7.536084).  Saving model ...\n",
      "Epoch Number 9\n",
      "train_loss 9.164 \n",
      "Validation Loss 7.536 \n",
      "********\n",
      "Validation loss decreased (7.536084 --> 7.215170).  Saving model ...\n",
      "Epoch Number 10\n",
      "train_loss 8.870 \n",
      "Validation Loss 7.215 \n",
      "********\n",
      "Validation loss decreased (7.215170 --> 6.893626).  Saving model ...\n",
      "Epoch Number 11\n",
      "train_loss 8.816 \n",
      "Validation Loss 6.894 \n",
      "********\n",
      "Validation loss decreased (6.893626 --> 6.852128).  Saving model ...\n",
      "Epoch Number 12\n",
      "train_loss 8.570 \n",
      "Validation Loss 6.852 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 13\n",
      "train_loss 8.459 \n",
      "Validation Loss 6.983 \n",
      "********\n",
      "Validation loss decreased (6.852128 --> 6.424107).  Saving model ...\n",
      "Epoch Number 14\n",
      "train_loss 8.226 \n",
      "Validation Loss 6.424 \n",
      "********\n",
      "Validation loss decreased (6.424107 --> 6.050152).  Saving model ...\n",
      "Epoch Number 15\n",
      "train_loss 8.139 \n",
      "Validation Loss 6.050 \n",
      "********\n",
      "Validation loss decreased (6.050152 --> 5.897966).  Saving model ...\n",
      "Epoch Number 16\n",
      "train_loss 8.002 \n",
      "Validation Loss 5.898 \n",
      "********\n",
      "Validation loss decreased (5.897966 --> 5.668874).  Saving model ...\n",
      "Epoch Number 17\n",
      "train_loss 7.945 \n",
      "Validation Loss 5.669 \n",
      "********\n",
      "Validation loss decreased (5.668874 --> 5.604811).  Saving model ...\n",
      "Epoch Number 18\n",
      "train_loss 7.701 \n",
      "Validation Loss 5.605 \n",
      "********\n",
      "Validation loss decreased (5.604811 --> 5.227251).  Saving model ...\n",
      "Epoch Number 19\n",
      "train_loss 7.757 \n",
      "Validation Loss 5.227 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 20\n",
      "train_loss 7.652 \n",
      "Validation Loss 5.253 \n",
      "********\n",
      "Validation loss decreased (5.227251 --> 5.112763).  Saving model ...\n",
      "Epoch Number 21\n",
      "train_loss 7.584 \n",
      "Validation Loss 5.113 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 22\n",
      "train_loss 7.484 \n",
      "Validation Loss 5.194 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 23\n",
      "train_loss 7.444 \n",
      "Validation Loss 5.152 \n",
      "********\n",
      "Validation loss decreased (5.112763 --> 5.046841).  Saving model ...\n",
      "Epoch Number 24\n",
      "train_loss 7.346 \n",
      "Validation Loss 5.047 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 25\n",
      "train_loss 7.266 \n",
      "Validation Loss 5.096 \n",
      "********\n",
      "Validation loss decreased (5.046841 --> 4.822402).  Saving model ...\n",
      "Epoch Number 26\n",
      "train_loss 7.314 \n",
      "Validation Loss 4.822 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 27\n",
      "train_loss 7.202 \n",
      "Validation Loss 4.845 \n",
      "********\n",
      "Validation loss decreased (4.822402 --> 4.739225).  Saving model ...\n",
      "Epoch Number 28\n",
      "train_loss 7.240 \n",
      "Validation Loss 4.739 \n",
      "********\n",
      "Validation loss decreased (4.739225 --> 4.521591).  Saving model ...\n",
      "Epoch Number 29\n",
      "train_loss 7.159 \n",
      "Validation Loss 4.522 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 30\n",
      "train_loss 7.073 \n",
      "Validation Loss 4.542 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 31\n",
      "train_loss 7.053 \n",
      "Validation Loss 4.619 \n",
      "********\n",
      "Validation loss decreased (4.521591 --> 4.344728).  Saving model ...\n",
      "Epoch Number 32\n",
      "train_loss 6.922 \n",
      "Validation Loss 4.345 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 33\n",
      "train_loss 6.921 \n",
      "Validation Loss 4.485 \n",
      "********\n",
      "Validation loss decreased (4.344728 --> 4.019758).  Saving model ...\n",
      "Epoch Number 34\n",
      "train_loss 6.788 \n",
      "Validation Loss 4.020 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 35\n",
      "train_loss 6.808 \n",
      "Validation Loss 4.157 \n",
      "********\n",
      "Validation loss decreased (4.019758 --> 3.951016).  Saving model ...\n",
      "Epoch Number 36\n",
      "train_loss 6.800 \n",
      "Validation Loss 3.951 \n",
      "********\n",
      "Validation loss decreased (3.951016 --> 3.941111).  Saving model ...\n",
      "Epoch Number 37\n",
      "train_loss 6.673 \n",
      "Validation Loss 3.941 \n",
      "********\n",
      "Validation loss decreased (3.941111 --> 3.852245).  Saving model ...\n",
      "Epoch Number 38\n",
      "train_loss 6.538 \n",
      "Validation Loss 3.852 \n",
      "********\n",
      "Validation loss decreased (3.852245 --> 3.635189).  Saving model ...\n",
      "Epoch Number 39\n",
      "train_loss 6.544 \n",
      "Validation Loss 3.635 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 40\n",
      "train_loss 6.516 \n",
      "Validation Loss 3.780 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 41\n",
      "train_loss 6.448 \n",
      "Validation Loss 3.648 \n",
      "********\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch Number 42\n",
      "train_loss 6.424 \n",
      "Validation Loss 3.811 \n",
      "********\n",
      "Validation loss decreased (3.635189 --> 3.400826).  Saving model ...\n",
      "Epoch Number 43\n",
      "train_loss 6.428 \n",
      "Validation Loss 3.401 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 44\n",
      "train_loss 6.398 \n",
      "Validation Loss 3.604 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 45\n",
      "train_loss 6.334 \n",
      "Validation Loss 3.664 \n",
      "********\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch Number 46\n",
      "train_loss 6.377 \n",
      "Validation Loss 3.637 \n",
      "********\n",
      "Validation loss decreased (3.400826 --> 3.371014).  Saving model ...\n",
      "Epoch Number 47\n",
      "train_loss 6.276 \n",
      "Validation Loss 3.371 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 48\n",
      "train_loss 6.356 \n",
      "Validation Loss 3.396 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 49\n",
      "train_loss 6.343 \n",
      "Validation Loss 3.401 \n",
      "********\n",
      "Validation loss decreased (3.371014 --> 3.227001).  Saving model ...\n",
      "Epoch Number 50\n",
      "train_loss 6.349 \n",
      "Validation Loss 3.227 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 51\n",
      "train_loss 6.313 \n",
      "Validation Loss 3.313 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 52\n",
      "train_loss 6.239 \n",
      "Validation Loss 3.485 \n",
      "********\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch Number 53\n",
      "train_loss 6.234 \n",
      "Validation Loss 3.410 \n",
      "********\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch Number 54\n",
      "train_loss 6.276 \n",
      "Validation Loss 3.413 \n",
      "********\n",
      "Validation loss decreased (3.227001 --> 3.173225).  Saving model ...\n",
      "Epoch Number 55\n",
      "train_loss 6.161 \n",
      "Validation Loss 3.173 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 56\n",
      "train_loss 6.126 \n",
      "Validation Loss 3.179 \n",
      "********\n",
      "Validation loss decreased (3.173225 --> 3.094821).  Saving model ...\n",
      "Epoch Number 57\n",
      "train_loss 6.038 \n",
      "Validation Loss 3.095 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 58\n",
      "train_loss 6.051 \n",
      "Validation Loss 3.234 \n",
      "********\n",
      "Validation loss decreased (3.094821 --> 2.981046).  Saving model ...\n",
      "Epoch Number 59\n",
      "train_loss 5.985 \n",
      "Validation Loss 2.981 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 60\n",
      "train_loss 6.115 \n",
      "Validation Loss 3.277 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 61\n",
      "train_loss 6.012 \n",
      "Validation Loss 3.010 \n",
      "********\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch Number 62\n",
      "train_loss 6.032 \n",
      "Validation Loss 3.071 \n",
      "********\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch Number 63\n",
      "train_loss 5.972 \n",
      "Validation Loss 3.138 \n",
      "********\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch Number 64\n",
      "train_loss 5.952 \n",
      "Validation Loss 3.107 \n",
      "********\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch Number 65\n",
      "train_loss 5.917 \n",
      "Validation Loss 3.012 \n",
      "********\n",
      "Validation loss decreased (2.981046 --> 2.887920).  Saving model ...\n",
      "Epoch Number 66\n",
      "train_loss 5.934 \n",
      "Validation Loss 2.888 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 67\n",
      "train_loss 5.948 \n",
      "Validation Loss 3.065 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 68\n",
      "train_loss 5.849 \n",
      "Validation Loss 2.968 \n",
      "********\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch Number 69\n",
      "train_loss 5.805 \n",
      "Validation Loss 2.996 \n",
      "********\n",
      "Validation loss decreased (2.887920 --> 2.860458).  Saving model ...\n",
      "Epoch Number 70\n",
      "train_loss 5.764 \n",
      "Validation Loss 2.860 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 71\n",
      "train_loss 5.777 \n",
      "Validation Loss 2.895 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 72\n",
      "train_loss 5.819 \n",
      "Validation Loss 2.934 \n",
      "********\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch Number 73\n",
      "train_loss 5.755 \n",
      "Validation Loss 2.952 \n",
      "********\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch Number 74\n",
      "train_loss 5.799 \n",
      "Validation Loss 3.078 \n",
      "********\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch Number 75\n",
      "train_loss 5.725 \n",
      "Validation Loss 2.884 \n",
      "********\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch Number 76\n",
      "train_loss 5.701 \n",
      "Validation Loss 2.912 \n",
      "********\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Epoch Number 77\n",
      "train_loss 5.727 \n",
      "Validation Loss 2.985 \n",
      "********\n",
      "EarlyStopping counter: 8 out of 7\n",
      "Epoch Number 78\n",
      "train_loss 5.669 \n",
      "Validation Loss 2.871 \n",
      "********\n",
      "Validation loss decreased (2.860458 --> 2.712778).  Saving model ...\n",
      "Epoch Number 79\n",
      "train_loss 5.645 \n",
      "Validation Loss 2.713 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 80\n",
      "train_loss 5.552 \n",
      "Validation Loss 2.870 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 81\n",
      "train_loss 5.559 \n",
      "Validation Loss 2.789 \n",
      "********\n",
      "Validation loss decreased (2.712778 --> 2.702612).  Saving model ...\n",
      "Epoch Number 82\n",
      "train_loss 5.503 \n",
      "Validation Loss 2.703 \n",
      "********\n",
      "Validation loss decreased (2.702612 --> 2.633528).  Saving model ...\n",
      "Epoch Number 83\n",
      "train_loss 5.485 \n",
      "Validation Loss 2.634 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 84\n",
      "train_loss 5.467 \n",
      "Validation Loss 2.847 \n",
      "********\n",
      "EarlyStopping counter: 2 out of 7\n",
      "Epoch Number 85\n",
      "train_loss 5.456 \n",
      "Validation Loss 2.942 \n",
      "********\n",
      "EarlyStopping counter: 3 out of 7\n",
      "Epoch Number 86\n",
      "train_loss 5.461 \n",
      "Validation Loss 2.708 \n",
      "********\n",
      "EarlyStopping counter: 4 out of 7\n",
      "Epoch Number 87\n",
      "train_loss 5.430 \n",
      "Validation Loss 2.965 \n",
      "********\n",
      "EarlyStopping counter: 5 out of 7\n",
      "Epoch Number 88\n",
      "train_loss 5.381 \n",
      "Validation Loss 2.864 \n",
      "********\n",
      "EarlyStopping counter: 6 out of 7\n",
      "Epoch Number 89\n",
      "train_loss 5.361 \n",
      "Validation Loss 2.661 \n",
      "********\n",
      "EarlyStopping counter: 7 out of 7\n",
      "Epoch Number 90\n",
      "train_loss 5.365 \n",
      "Validation Loss 2.926 \n",
      "********\n",
      "EarlyStopping counter: 8 out of 7\n",
      "Epoch Number 91\n",
      "train_loss 5.347 \n",
      "Validation Loss 2.757 \n",
      "********\n",
      "EarlyStopping counter: 9 out of 7\n",
      "Epoch Number 92\n",
      "train_loss 5.345 \n",
      "Validation Loss 2.819 \n",
      "********\n",
      "EarlyStopping counter: 10 out of 7\n",
      "Epoch Number 93\n",
      "train_loss 5.339 \n",
      "Validation Loss 2.942 \n",
      "********\n",
      "EarlyStopping counter: 11 out of 7\n",
      "Epoch Number 94\n",
      "train_loss 5.295 \n",
      "Validation Loss 2.703 \n",
      "********\n",
      "EarlyStopping counter: 12 out of 7\n",
      "Epoch Number 95\n",
      "train_loss 5.343 \n",
      "Validation Loss 2.663 \n",
      "********\n",
      "EarlyStopping counter: 13 out of 7\n",
      "Epoch Number 96\n",
      "train_loss 5.242 \n",
      "Validation Loss 2.725 \n",
      "********\n",
      "EarlyStopping counter: 14 out of 7\n",
      "Epoch Number 97\n",
      "train_loss 5.253 \n",
      "Validation Loss 2.729 \n",
      "********\n",
      "EarlyStopping counter: 15 out of 7\n",
      "Epoch Number 98\n",
      "train_loss 5.166 \n",
      "Validation Loss 2.775 \n",
      "********\n",
      "Validation loss decreased (2.633528 --> 2.620618).  Saving model ...\n",
      "Epoch Number 99\n",
      "train_loss 5.140 \n",
      "Validation Loss 2.621 \n",
      "********\n",
      "EarlyStopping counter: 1 out of 7\n",
      "Epoch Number 100\n",
      "train_loss 5.152 \n",
      "Validation Loss 2.640 \n",
      "********\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "    \n",
    "loss_fn = nn.L1Loss(reduction='none')\n",
    "\n",
    "model = BB_model(device,coordConv=False).to(device)\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=0.006)\n",
    "    \n",
    "update_optimizer(optimizer, 0.001)\n",
    "    \n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    0.006,\n",
    "    n_epoch,\n",
    "    steps_per_epoch=len(train_ds)//BACTH_SIZE\n",
    ")\n",
    "\n",
    "    \n",
    "trainLossModel2,valLossModel2=main_training(model=model,patience=7,optimizer=optimizer,scheduler=scheduler,train_dl=trainLoader,test_dl=testLoader,epochs=n_epoch,loss_fn=loss_fn)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_x = np.arange(0, n_epoch, 1)\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "plt.plot(epoch_x, trainLossModel2, label=\"Standard\", lw=3)\n",
    "plt.plot(epoch_x, trainLossModel1, label=\"CoordConv\", lw=3)\n",
    "plt.legend()\n",
    "plt.title(\"Supervised Training Regression Error\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LuminEye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
